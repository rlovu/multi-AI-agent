{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4861bd20",
   "metadata": {},
   "source": [
    "## ëŒ€ìš©ëŸ‰ ë¹„ì •í˜• ë°ì´í„° ê¸°ë°˜ Advanced RAG êµ¬ì¶• ë° í‰ê°€\n",
    "#### ê°•ì˜ ëª©í‘œ\n",
    "1. **Real-World Data Handling**: ë‚˜ë¬´ìœ„í‚¤(êµ¬ì–´ì²´/ì§€ì‹) FinePDFs(ë¬¸ì–´ì²´/ì „ë¬¸ë¬¸ì„œ)ê°€ ì„ì¸ ë‘ê°œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "2. **Beyond Keyword Search**: ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­(BM25)ê³¼ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰(Vector Search)ì˜ ê²°ì •ì  ì°¨ì´ë¥¼ ì²´ê°í•©ë‹ˆë‹¤.\n",
    "3. **Hybrid Search**: BM25ì™€ Vector Searchë¥¼ ê²°í•©í•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
    "4. **Advanced Pipeline**: Retriever + Reranker êµ¬ì¡°ë¥¼ í†µí•´ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ê·¹ëŒ€í™”í•˜ëŠ” ê¸°ë²•ì„ ìµí™ë‹ˆë‹¤.\n",
    "5. **Query Decomposition**: ë³µì¡í•œ ì§ˆì˜ë¥¼ ë¶„í•´í•˜ì—¬ ë” ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì–»ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "6. **Data-Driven Evalution**: ì •ë‹µì§€ê°€ ì—†ëŠ” ìƒí™©ì—ì„œ LLMì„ ì´ìš©í•´ *í•©ì„± ë°ì´í„°ì…‹(Synthetic Testset)*ì„ ë§Œë“¤ê³  í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "#### ì‚¬ìš© ëª¨ë¸ ë° ë°ì´í„°\n",
    "- **LLM**: gpt-5-mini (High Performance & Low Cost)\n",
    "- **Data**: heegyu/namuwiki (General Knowledge) + HuggingFaceFW/finepdfs-edu (Domain Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4f814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (Jupyter í™˜ê²½ ê¶Œì¥ ë°©ì‹)\n",
    "\n",
    "# ë²„ì „ì„ ëª…ì‹œí•˜ì—¬ í˜¸í™˜ì„± ë¬¸ì œ ë°©ì§€\n",
    "\n",
    "%pip install -q \\\n",
    "    langchain==0.3.14 \\\n",
    "    langchain-openai==0.2.14 \\\n",
    "    langchain-huggingface==0.1.2 \\\n",
    "    langchain-community==0.3.14 \\\n",
    "    ragas==0.2.10 \\\n",
    "    datasets \\\n",
    "    sentence-transformers \\\n",
    "    tiktoken \\\n",
    "    rank_bm25 \\\n",
    "    pandas \\\n",
    "    faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0b2324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# API_KEY ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d7850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print API key\n",
    "# print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY'][:-15]}\" + \"*\" * 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbcaef5",
   "metadata": {},
   "source": [
    "## 1. Data Loading: 'í˜„ì‹¤ì ì¸' ë°ì´í„° ë¯¹ì‹±(Mixing)\n",
    "í˜„ì‹¤ì—ëŠ” ê¹”ë”í•˜ê²Œ ì •ì œëœ ë°ì´í„°ë§Œ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. **ì§€ì‹ ë°±ê³¼(Wiki)** ìŠ¤íƒ€ì¼ê³¼ **ë³´ê³ ì„œ(PDF)** ìŠ¤íƒ€ì¼ì˜ í…ìŠ¤íŠ¸ê°€ ì„ì—¬ì„œ, ë‚œì´ë„ê°€ ë†’ì€ í†µí•© ê²€ìƒ‰ í™˜ê²½ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5681a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘...\n",
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ 986677ê°œ ë¬¸ì„œ\n",
      "   - Wiki ì˜ˆì‹œ(ì´ 867024ê°œ): [ì¶œì²˜: ë‚˜ë¬´ìœ„í‚¤] ì œëª©: !\n",
      "\n",
      "#redirect ëŠë‚Œí‘œ\n",
      "...\n",
      "   - PDF ì˜ˆì‹œ(ì´ 119653ê°œ): [ì¶œì²˜: ë‚˜ë¬´ìœ„í‚¤] ì œëª©: 04-ALICIA\n",
      "\n",
      "[[íŒŒì¼:external/vignette4.wikia.nocookie.net/Alicia_sche...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "print(\"ğŸ“¥ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘...\")\n",
    "\n",
    "raw_docs = []\n",
    "\n",
    "# [Source A] ë‚˜ë¬´ìœ„í‚¤ (General Knowledge)\n",
    "# íŠ¹ì§•: êµ¬ì–´ì²´, ë‹¤ì–‘í•œ ì£¼ì œ, ë©”íƒ€ë°ì´í„°ì— ì œëª© í¬í•¨\n",
    "wiki_stream = load_dataset(\"heegyu/namuwiki\", split=\"train\", streaming=True)\n",
    "for idx, data in enumerate(wiki_stream):\n",
    "    # if idx >= 10: break  # ì‹¤ìŠµ ì†ë„ë¥¼ ìœ„í•´ 100ê°œë§Œ ì‚¬ìš©, Memory & Computation ì—¬ìœ ê°€ ìˆë‹¤ë©´ ì „ë¶€ ì¨ë³´ê¸°\n",
    "    # print(f\"[{idx+1}/100] {data}\")\n",
    "    content = f\"[ì¶œì²˜: ë‚˜ë¬´ìœ„í‚¤] ì œëª©: {data['title']}\\n\\n{data['text']}\"\n",
    "    raw_docs.append(Document(page_content=content, metadata={\"source\": \"namuwiki\", \"title\": data['title']}))\n",
    "\n",
    "length_of_wiki = len(raw_docs)\n",
    "\n",
    "# for i, doc in enumerate(raw_docs):\n",
    "#     print(f\"[{i+1}/10] {doc}\")\n",
    "\n",
    "# [Source B] FinePDFs-Edu (Domain Documents)\n",
    "# íŠ¹ì§•: ë¬¸ì–´ì²´, ì „ë¬¸ìš©ì–´, ì„œì‹(Header/Footer) ë…¸ì´ì¦ˆ ì¡´ì¬\n",
    "pdf_stream = load_dataset(\"HuggingFaceFW/finepdfs-edu\", \"kor_Hang\", split=\"train\", streaming=True)\n",
    "for idx, data in enumerate(pdf_stream):\n",
    "    # if idx >= 100: break\n",
    "    # PDFëŠ” ì œëª©ì´ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš°ê°€ ë§ì•„ URLì„ ë©”íƒ€ë°ì´í„°ë¡œ ì‚¬ìš©\n",
    "    raw_docs.append(Document(page_content=data['text'], metadata={\"source\": \"finepdf\", \"url\": data['url']}))\n",
    "\n",
    "length_of_pdf = len(raw_docs) - length_of_wiki\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {len(raw_docs)}ê°œ ë¬¸ì„œ\")\n",
    "print(f\"   - Wiki ì˜ˆì‹œ(ì´ {length_of_wiki}ê°œ): {raw_docs[0].page_content[:80]}...\")\n",
    "print(f\"   - PDF ì˜ˆì‹œ(ì´ {length_of_pdf}ê°œ): {raw_docs[length_of_wiki].page_content[:80]}...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d49fc6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2587974",
   "metadata": {},
   "source": [
    "## 2. Advanced Chunking Strategy\n",
    "PPTì—ì„œ ê°•ì¡°í•œ **Chunking** ì „ëµì…ë‹ˆë‹¤.\n",
    "- **Attention Dilution ë°©ì§€**: ë„ˆë¬´ ê¸¸ë©´ LLMì´ í•µì‹¬ì„ ë†“ì¹©ë‹ˆë‹¤.\n",
    "- **Context Overlap**: ë¬¸ë§¥ì´ ëŠê¸°ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ Chunk_overlapì„ ë‘¡ë‹ˆë‹¤.\n",
    "- **Separators**: ë¬¸ë‹¨(\\n\\n) â†’ ì¤„ë°”ê¿ˆ(\\n) â†’ ë¬¸ì¥(.) ìˆœì„œë¡œ ì˜ë¯¸ ë‹¨ìœ„ë¥¼ ë³´ì¡´í•˜ë©° ìë¦…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PPT ì‹¤ë¬´ íŒ ë°˜ì˜: ì˜ë¯¸ ë‹¨ìœ„ ë³´ì¡´ì„ ìœ„í•œ ê³„ì¸µì  Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,  # ê²€ìƒ‰ì— ì ì ˆí•œ í¬ê¸° (í† í° ê¸°ì¤€ ì•„ë‹˜, ê¸€ì ìˆ˜ ê¸°ì¤€)\n",
    "    chunk_overlap=100,  # ì•ë’¤ ë¬¸ë§¥ ì—°ê²°ì„ ìœ„í•œ ì˜¤ë²„ë©\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # ì˜ë¯¸ ë‹¨ìœ„ ìš°ì„  ìˆœìœ„\n",
    ")\n",
    "\n",
    "splitted_docs = text_splitter.split_documents(raw_docs)\n",
    "print(f\"âœ‚ï¸ ì²­í‚¹ ê²°ê³¼: {len(raw_docs)}ê°œ ë¬¸ì„œ â†’ {len(splitted_docs)}ê°œ ì²­í¬ë¡œ ë¶„í• ë¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a613e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871fb8fe",
   "metadata": {},
   "source": [
    "## 3. ê²€ìƒ‰ ì—”ì§„ êµ¬ì¶•: BM25, Vector, Hybrid\n",
    "ì„¸ê°€ì§€ ê²€ìƒ‰ ë°©ì‹ì„ êµ¬ì¶•í•˜ê³  ë¹„êµí•©ë‹ˆë‹¤.\n",
    "\n",
    "|ë°©ì‹|íŠ¹ì§•|ì¥ì |ë‹¨ì |\n",
    "|----|----|----|----|\n",
    "|**BM25**|í‚¤ì›Œë“œ ë§¤ì¹­|ì •í™•í•œ ìš©ì–´ ê²€ìƒ‰ì— ê°•í•¨|ë™ì˜ì–´/ìœ ì‚¬ì–´ ì¸ì‹ ë¶ˆê°€|\n",
    "|**Vector**|ì˜ë¯¸ ê¸°ë°˜|ë¬¸ë§¥ì  ìœ ì‚¬ì„± íŒŒì•…|íŠ¹ì • í‚¤ì›Œë“œ ê²€ìƒ‰ì— ì•½í•¨|\n",
    "|**Hybrid**|BM25 + Vector ê²°í•©|ë‘ ì¥ì  ê²°í•©|ê°€ì¤‘ì¹˜ íŠœë‹ í•„ìš”|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e460837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 1. BM25 Retriever êµ¬ì¶•(í‚¤ì›Œë“œ ê¸°ë°˜)\n",
    "bm25_retriever = BM25Retriever.from_documents(splitted_docs)\n",
    "bm25_retriever.k = 5  # í›„ë³´êµ°ì„ ë„‰ë„‰í•˜ê²Œ\n",
    "\n",
    "# 2. Vector Store êµ¬ì¶• (ì˜ë¯¸ ê¸°ë°˜, FAISS ì‚¬ìš©)\n",
    "# OpenAI Embedding ì‚¬ìš©\n",
    "openai_embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splitted_docs,\n",
    "    embedding=openai_embedding\n",
    ")\n",
    "vector_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(\"âœ… BM25 & Vector(FAISS) ê²€ìƒ‰ ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666e3ed",
   "metadata": {},
   "source": [
    "#### 3.1 ğŸ†• Hybrid Search êµ¬í˜„ (PPT 23-24 ìŠ¬ë¼ì´ë“œ)\n",
    "**Î»â€¢BM25 + (1-Î»)â€¢Vector** í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì…ë‹ˆë‹¤.\n",
    "```\n",
    "ìµœì¢… ìŠ¤ì½”ì–´ = Î± * BM25_score + (1 - Î±) * Vector_score\n",
    "```\n",
    "LangChainì˜ EnsembleRetrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ RRF(Reciprocal Rank Fusion) ë°©ì‹ìœ¼ë¡œ ê²°í•©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "# Hybrid Retriever: BM25(í‚¤ì›Œë“œ) + Vector(ì˜ë¯¸) ê²°í•©\n",
    "# weights: [BM25 ê°€ì¤‘ì¹˜, Vector ê°€ì¤‘ì¹˜] - í•©ì´ 1ì´ ë  í•„ìš”ëŠ” ì—†ìŒ\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.4, 0.6]  # Vectorì— ì•½ê°„ ë” ê°€ì¤‘ì¹˜ (ì‚¬ì „ ì •ì˜ëœ ì§ˆë¬¸ Coverageì— ë”°ë¼ ì¡°ì •)\n",
    ")\n",
    "\n",
    "print(\"âœ… Hybrid Search ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"   - BM25 ê°€ì¤‘ì¹˜: 0.4 (í‚¤ì›Œë“œ ë§¤ì¹­)\")\n",
    "print(\"   - Vector ê°€ì¤‘ì¹˜: 0.6 (ì˜ë¯¸ ê¸°ë°˜)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45bcf72",
   "metadata": {},
   "source": [
    "#### 3.2 ê²€ìƒ‰ ë°©ì‹ ë¹„êµ ì‹¤í—˜\n",
    "ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ ì„¸ê°€ì§€ ê²€ìƒ‰ ë°©ì‹ì˜ ê²°ê³¼ë¥¼ ë¹„êµí•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_retrievers(query: str):\n",
    "    \"\"\"ì„¸ê°€ì§€ ê²€ìƒ‰ ë°©ì‹ ê²°ê³¼ ë¹„êµ\"\"\"\n",
    "    print(f\"ğŸ” ì§ˆë¬¸: '{query}'\\n\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    results = {\n",
    "        \"BM25 (í‚¤ì›Œë“œ)\": bm25_retriever.invoke(query),\n",
    "        \"Vector (ì˜ë¯¸)\": vector_retriever.invoke(query),\n",
    "        \"Hybrid (ê²°í•©)\": hybrid_retriever.invoke(queyr)\n",
    "    }\n",
    "\n",
    "    for method, docs in results.items():\n",
    "        print(f\"\\nğŸ“Œ [{method}] ìƒìœ„ 3ê°œ ê²°ê³¼:\")\n",
    "        print(\"-\" * 40)\n",
    "        for i, doc in enumerate(docs[:3], 1):\n",
    "            source = doc.metadata.get('source', 'unknown')\n",
    "            preview = doc.page_content[:100].replace('\\n', ' ')\n",
    "            print(f\"   {i}. [{source}] {preview}...\")\n",
    "        if not docs:\n",
    "            print(\"   â†’ ê²°ê³¼ ì—†ìŒ\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ 1: ì˜ë¯¸ë¡ ì  ì§ˆë¬¸(Vectorê°€ ìœ ë¦¬)\n",
    "results1 = compare_retrievers(\"í”„ë¦°í„° ì¶”ì²œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf9847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 2: íŠ¹ì • í‚¤ì›Œë“œ ì§ˆë¬¸ (BM25ê°€ ìœ ë¦¬)\n",
    "results2 = compare_retrievers(\"ëŒ€í•œë¯¼êµ­ í—Œë²• ì œ1ì¡°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 3: ë³µí•©ì ì¸ ì§ˆë¬¸ (Hybridê°€ ìœ ë¦¬)\n",
    "results3 = compare_retrievers(\"ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ê³¼ ë¯¸ë˜ ì „ë§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2109de",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23377ba5",
   "metadata": {},
   "source": [
    "## 4. Advanced Pipeline: Reranker ë„ì…\n",
    "\"Rerankì˜ ê°œë…\"\n",
    "|ë‹¨ê³„|ëª¨ë¸|íŠ¹ì§•|\n",
    "|----|----|----|\n",
    "|**1ì°¨ ê²€ìƒ‰(Retriever)**|Bi-Encoder|ë¹ ë¦„, ëŒ€ëŸ‰ í›„ë³´ ì¶”ì¶œ|\n",
    "|**2ì°¨ ì •ë ¬(Reranker)**|Cross-Encoder|ëŠë¦¼, ì •ë°€í•œ ê´€ë ¨ì„± í‰ê°€|\n",
    "\n",
    "ì´ **2-Stage Retrieval** êµ¬ì¡°ê°€ í˜„ì—…ì—ì„œ ê°€ì¥ ë§ì´ ì“°ì´ëŠ” ê³ ì„±ëŠ¥ íŒ¨í„´ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8fe4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- ì˜¨í”„ë ˜ CrossEncoder Reranker (ì§ì ‘ ëª¨ë¸ ë¡œë“œ, ì°¸ê³ ìš©) ---\n",
    "# from sentence_transformers import CrossEncoder\n",
    "# from langchain.retrievers.document_compressors import BaseDocumentCompressor\n",
    "# from langchain.schema import Document\n",
    "# from typing import List, Sequence\n",
    "# from pydantic import PrivateAttr\n",
    "\n",
    "# class CrossEncoderReranker(BaseDocumentCompressor):\n",
    "#     \"\"\"Cross-Encoder ê¸°ë°˜ Reranker (ì˜¨í”„ë ˜)\"\"\"\n",
    "#     model_name: str = \"BAAI/bge-reranker-base\"\n",
    "#     top_n: int = 3\n",
    "#     _model: CrossEncoder = PrivateAttr()\n",
    "\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self._model = CrossEncoder(self.model_name)\n",
    "    \n",
    "#     def compress_documents(self, documents: Sequence[Document], query: str, callbacks=None) -> List[Document]:\n",
    "#         if not documents:\n",
    "#             return []\n",
    "#         pairs = [(query, doc.page_content) for doc in documents]\n",
    "#         scores = self._model.predict(pairs)\n",
    "#         scored_docs = list(zip(scores, documents))\n",
    "#         scored_docs.sort(key=lambda x: x[0], reverse=True)\n",
    "#         return [doc for _, doc in scored_docs[:self.top_n]]\n",
    "    \n",
    "# # ì˜¨í”„ë ˜ Reranker ì‚¬ìš© ì˜ˆì‹œ (ì°¸ê³ ìš©)\n",
    "# reranker = CrossEncoderReranker(model_name=\"BAAI/bge-reranker-base\", top_n=3)\n",
    "\n",
    "# # --- Cohere Rerank API ì§ì ‘ í˜¸ì¶œ ì»¤ìŠ¤í…€ Reranker ---\n",
    "import cohere\n",
    "from langchain_core.documents.compressor import BaseDocumentCompressor\n",
    "from langchain.schema import Document\n",
    "from typing import List, Sequence\n",
    "from pydantic import PrivateAttr\n",
    "\n",
    "class CohereReranker(BaseDocumentCompressor):\n",
    "    cohere_api_key: str\n",
    "    top_n: int = 3\n",
    "    model: str = \"rerank-multilingual-v3.0\"\n",
    "    _client: cohere.Client = PrivateAttr()\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._client = cohere.Client(self.cohere_api_key)\n",
    "    \n",
    "    def compress_documents(self, documents: Sequence[Document], query: str, callbacks=None) -> List[Document]:\n",
    "        if not documents:\n",
    "            return []\n",
    "        docs_text = [doc.page_content for doc in documents]\n",
    "        results = self._client.rerank(\n",
    "            model=self.model,\n",
    "            query=query,\n",
    "            documents=docs_text,\n",
    "            top_n=self.top_n\n",
    "        )\n",
    "        return [documents[r.index] for r in results.results]\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "cohere_api_key = os.environ['COHERE_API_KEY']\n",
    "reranker = CohereReranker(cohere_api_key=cohere_api_key, top_n=3)\n",
    "\n",
    "# Base Retriever: Hybridì—ì„œ í›„ë³´êµ°ì„ ë„‰ë„‰í•˜ê²Œ(K=10) ê°€ì ¸ì˜´\n",
    "from  langchain.retrievers import EnsembleRetriever\n",
    "hybrid_retriever_wide = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        BM25Retriever.from_documents(splitted_docs, k=10),\n",
    "        vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "    ],\n",
    "    weights=[0.4, 0.6]\n",
    ")\n",
    "\n",
    "# ìµœì¢… Rerank Pipeline\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "rerank_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=reranker,\n",
    "    base_retriever=hybrid_retriever_wide\n",
    ")\n",
    "\n",
    "print(\"âœ… Advanced RAG Pipeline (Cohere Reranker, ì§ì ‘ í˜¸ì¶œ) êµ¬ì¶• ì™„ë£Œ!\")\n",
    "print(\"   - 1ì°¨: Hybrid Searchë¡œ 20ê°œ í›„ë³´ ì¶”ì¶œ\")\n",
    "print(\"   - 2ì°¨: Cohere Rerankë¡œ ìƒìœ„ 3ê°œ ì¬ì •ë ¬\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fce7c3",
   "metadata": {},
   "source": [
    "#### 5. ğŸ†• Query Decomposition (PPT 41-43 ìŠ¬ë¼ì´ë“œ)\n",
    "**ì¿¼ë¦¬ ë¶„í•´(Query Decomposition)** ê¸°ë²•\n",
    "\n",
    "ë³µì¡í•œ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê°œì˜ ë‹¨ìˆœí•œ í•˜ìœ„ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´í•˜ì—¬:\n",
    "1. ê° í•˜ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "2. ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±\n",
    "**ì˜ˆì‹œ**:\n",
    "- ì›ë³¸: \"ì‚¼ì„±ì „ìë‘ í•˜ì´ë‹‰ìŠ¤ ê°€ê²© ìƒìŠ¹ ìš”ì¸ ë¹„êµí•´ë´\"\n",
    "- ë¶„í•´:\n",
    "    - \"ì‚¼ì„±ì „ì ê°€ê²© ìƒìŠ¹ ìš”ì¸\"\n",
    "    - \"í•˜ì´ë‹‰ìŠ¤ ê°€ê²© ìƒìŠ¹ ìš”ì¸\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()  # OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©\n",
    "\n",
    "def decompose_query(query: str) -> list:\n",
    "    \"\"\"ë³µì¡í•œ ì¿¼ë¦¬ë¥¼ í•˜ìœ„ ì¿¼ë¦¬ë“¤ë¡œ ë¶„í•´\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"ë‹¹ì‹ ì€ ë³µì¡í•œ ì§ˆë¬¸ì„ í•˜ìœ„ ì§ˆë¬¸ë“¤ë¡œ ë¶„í•´í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ì£¼ì–´ì§„ ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ì í•©í•œ 2~4ê°œì˜ í•˜ìœ„ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´í•´ì£¼ì„¸ìš”.\n",
    "ê° í•˜ìœ„ ì§ˆë¬¸ì€ ë…ë¦½ì ìœ¼ë¡œ ê²€ìƒ‰ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì›ë³¸ ì§ˆë¬¸: {query}\n",
    "\n",
    "í•˜ìœ„ ì§ˆë¬¸ë“¤ 'í•œ ì¤„ì— í•˜ë‚˜ì”©, ë²ˆí˜¸ ì—†ì´):\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "    sub_queries = [q.strip() for q in result.strip().split('\\n') if q.strip()]\n",
    "    return sub_queries\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "complex_query = \"ì‚¼ì„±ì „ìì™€ SKí•˜ì´ë‹‰ìŠ¤ì˜ ë°˜ë„ì²´ ê¸°ìˆ ë ¥ê³¼ ì‹œì¥ ì ìœ ìœ¨ì„ ë¹„êµ ë¶„ì„í•´ì¤˜.\"\n",
    "sub_queries = decompose_query(complex_query)\n",
    "\n",
    "print(f\"ğŸ“ ì›ë³¸ ì§ˆë¬¸:{complex_query}\")\n",
    "print(f\"\\nğŸ”€ ë¶„í•´ëœ í•˜ìœ„ ì§ˆë¬¸ë“¤:\")\n",
    "for i, sq in enumerate(sub_queries, 1):\n",
    "    print(f\"    {i}. {sq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eccc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_decomposition(query: str, retriever, top_k: int = 3) -> list:\n",
    "    \"\"\"\n",
    "    ì¿¼ë¦¬ ë¶„í•´ + ê²€ìƒ‰ + ê²°ê³¼ í†µí•© íŒŒì´í”„ë¼ì¸\n",
    "    \"\"\"\n",
    "    # 1. ì¿¼ë¦¬ ë¶„í•´\n",
    "    sub_queries = decompose_query(query)\n",
    "    print(f\"ğŸ”€ '{query[:30]}...' â†’ {len(sub_queries)}ê°œ í•˜ìœ„ ì¿¼ë¦¬ë¡œ ë¶„í•´\")\n",
    "\n",
    "    #2. ê° í™”ìœ„ ì¿¼ë¦¬ì— ëŒ€í•´ ê²€ìƒ‰\n",
    "    all_docs = []\n",
    "    seen_contents = set()\n",
    "\n",
    "    for sq in sub_queries:\n",
    "        docs = retriever.invoke(sq)\n",
    "        for doc in docs:\n",
    "            # ì¤‘ë³µ ì œê±°\n",
    "            content_hash = hash(doc.page_content[:200])\n",
    "            if content_hash not in seen_contents:\n",
    "                seen_contents.add(content_hash)\n",
    "                all_docs.append(doc)\n",
    "    \n",
    "    print(f\"ğŸ—’ï¸ ì´ {len(all_docs)}ê°œ ê³ ìœ  ë¬¸ì„œ ê²€ìƒ‰ë¨\")\n",
    "\n",
    "    # 3. Rerankerë¡œ ìµœì¢… ì •ë ¬ (ì„ íƒì )\n",
    "    if len(all_docs) > top_k:\n",
    "        final_docs = reranker.compress_documents(all_docs, query)\n",
    "    else:\n",
    "        final_docs = all_docs[:top_k]\n",
    "    \n",
    "    return final_docs\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "docomposed_results = retrieve_with_decomposition(\n",
    "    \"ì¸ê³µì§€ëŠ¥ì˜ ì¥ë‹¨ì ê³¼ ë¯¸ë˜ ë°œì „ ë°©í–¥ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\",\n",
    "    hybrid_retriever\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Œ ìµœì¢… ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "for i, doc in enumerate(decomposed_results, 1):\n",
    "    print(f\"   {i}. [{doc.metadata.get('source', 'unknown')}] {doc.page_content[:80]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e37f90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e4e52",
   "metadata": {},
   "source": [
    "#### 6. RAG Chain êµ¬ì„± ë° í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59337af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# ìµœì¢… Generation Chain ì—°ê²°\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retruever=rerank_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "response = rag_chain.invoke({\"query\": \"í•œêµ­ì˜ êµìœ¡ ì œë„ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\"})\n",
    "print(f\"ğŸ¤– ë‹µë³€:\\n{response['result']}\")\n",
    "print(f\"\\nğŸ—’ï¸ ì°¸ì¡°í•œ ë¬¸ì„œ ì¶œì²˜: {[doc.metadata.get('source', 'unknown') for doc in response['source_documents']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8385476d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0cf6c2",
   "metadata": {},
   "source": [
    "#### 7. Synthetic Testset Generation (í‰ê°€ ë°ì´í„° ìƒì„±)\n",
    "\n",
    "í‰ê°€ íŒŒíŠ¸ ì…ë‹ˆë‹¤.(without RAGAS)\n",
    "\n",
    "\"ì •ë‹µì§€(Ground Truth)ê°€ ì—†ëŠ”ë° ì–´ë–»ê²Œ í‰ê°€í•˜ë‚˜ìš”?\" â†’ **LLMì„ ì‹œì¼œì„œ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì œë¥¼ ì¶œì œí•˜ë©´ ë©ë‹ˆë‹¤.**\n",
    "\n",
    "ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 'ì§ˆë¬¸'ê³¼ 'ëª¨ë²” ë‹µì•ˆ'ì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94318f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def generate_test_questions(docs, num_questions=5):\n",
    "    \"\"\" ë¬¸ì„œì—ì„œ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸/ë‹µë³€ ìŒ ìƒì„±\"\"\"\n",
    "\n",
    "    # ë¬¸ì„œ ë‚´ìš© í•©ì¹˜ê¸°\n",
    "    combined_text = \"\\n\\n\".join([doc.page_content for doc in docs[:30]])\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°\n",
    "    if len(combined_text) > 15000:\n",
    "        combined_text = combined_text[:15000]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0.7,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"ë‹¹ì‹ ì€ ë¬¸ì„œë¥¼ ì½ê³  í…ŒìŠ¤íŠ¸ ë¬¸ì œë¥¼ ì¶œì œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì½ê³  {num_questions}ê°œì˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë¬¸ì„œ:\n",
    "{combined_text}\n",
    "\n",
    "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´)\n",
    "[\n",
    "    {{\"question\": \"ì§ˆë¬¸1\", \"answer\": \"ë‹µë³€1\"}},\n",
    "    {{\"question\": \"ì§ˆë¬¸2\", \"answer\": \"ë‹µë³€2\"}}\n",
    "]\n",
    "\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "\n",
    "    # JSON íŒŒì‹±\n",
    "    try:\n",
    "        # í˜¹ì‹œ ```json``` ê°™ì€ ë§ˆí¬ë‹¤ìš´ì´ ìˆìœ¼ë©´ ì œê±°\n",
    "        result = result.strip()\n",
    "        if result.startswith(\"```\"):\n",
    "            result = result.split(\"```\")[1]\n",
    "            if result.startswith(\"json\"):\n",
    "                result = result[4:]\n",
    "        \n",
    "        qa_pairs = json.loads(result)\n",
    "        return qa_pairs\n",
    "    except:\n",
    "        print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ ì‘ë‹µ:\")\n",
    "        print(result)\n",
    "        return []\n",
    "\n",
    "# ì‹¤í–‰\n",
    "print(\"ğŸ¤– AIê°€ ë¬¸ì„œë¥¼ ì½ê³  ì‹œí—˜ ë¬¸ì œë¥¼ ì¶œì œ ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "print(\"    âŒ› ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...\")\n",
    "\n",
    "qa_pairs = generate_test_questions(splitted_docs, num_questions=5)\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "test_df = pd.DataFrame(qa_pairs)\n",
    "test_df.columns = ['user_input', 'reference']\n",
    "\n",
    "print(f\"\\nâœ… {len(test_df)}ê°œì˜ í…ŒìŠ¤íŠ¸ ë¬¸ì œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1646c432",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85c65e",
   "metadata": {},
   "source": [
    "#### 8. ğŸ†• Evaluation (ì •ëŸ‰ í‰ê°€) + ë©”íŠ¸ë¦­ í•´ì„ ê°€ì´ë“œ\n",
    "\n",
    "PPT 56ë²ˆ ìŠ¬ë¼ì´ë“œì˜ ì£¼ìš” í‰ê°€ ë©”íŠ¸ë¦­ì„ ì‹¤ì œë¡œ ì¸¡ì •í•©ë‹ˆë‹¤. ë‹¤ë§Œ ì‹¬í”Œí•¨ì„ ìœ„í•´ llm-as-judgeë¥¼ ì‚¬ìš©í•´ë´…ì‹œë‹¤!\n",
    "\n",
    "#### ğŸ“Š RAGAS í•µì‹¬ ë©”íŠ¸ë¦­ í•´ì„ ê°€ì´ë“œ\n",
    "\n",
    "|ë©”íŠ¸ë¦­|ì¸¡ì •ëŒ€ìƒ|ì˜ë¯¸|ë‚®ì„ ë•Œ ì›ì¸|\n",
    "|----|----|----|----|\n",
    "|**Faithfulness**|ìƒì„± ëª¨ë“ˆ|ë‹µë³€ì´ ê²€ìƒ‰ëœ Contextì— **ì¶©ì‹¤**í•œê°€? (í• ë£¨ì‹œë„¤ì´ì…˜ ì²´í¬)|LLMì´ Context ì™¸ ì •ë³´ë¡œ ë‹µë³€ ìƒì„±|\n",
    "|**Answer Relevancy**|ìƒì„± ëª¨ë“ˆ|ë‹µë³€ì´ ì§ˆë¬¸ì˜ **ì˜ë„ì— ë¶€í•©**í•˜ëŠ”ê°€?|ì§ˆë¬¸ê³¼ ë¬´ê´€í•œ ë‚´ìš© í¬í•¨|\n",
    "|**Context Recall**|ê²€ìƒ‰ ëª¨ë“ˆ|ì •ë‹µì— í•„ìš”í•œ ì •ë³´ê°€ Contextì— **í¬í•¨**ë˜ì—ˆëŠ”ê°€?|Retrieverê°€ ê´€ë ¨ ë¬¸ì„œ ëˆ„ë½|\n",
    "|**Context Precision**|ê²€ìƒ‰ ëª¨ë“ˆ|ê²€ìƒ‰ëœ Contextê°€ **ê´€ë ¨ì„± ë†’ì€ ìˆœì„œ**ë¡œ ì •ë ¬ë˜ì—ˆëŠ”ê°€?|ë…¸ì´ì¦ˆ ë¬¸ì„œê°€ ìƒìœ„ì— ìœ„ì¹˜|\n",
    "\n",
    "#### ğŸ¯ ëª©í‘œ ì ìˆ˜ ê°€ì´ë“œë¼ì¸\n",
    "- **0.8 ì´ìƒ**: ìš°ìˆ˜ (Production Ready)\n",
    "- **0.6-0.8**: ì–‘í˜¸ (ê°œì„  ì—¬ì§€ ìˆìŒ)\n",
    "- **0.6 ë¯¸ë§Œ**: ê°œì„  í•„ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846e2556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS ì—†ì´ ê°„ë‹¨í•œ í‰ê°€ (LLM ê¸°ë°˜)\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def simple_evalute(question, answer, reference, context):\n",
    "    \"\"\"LLMì„ ì´ìš©í•œ ê°„ë‹¨í•œ í‰ê°€\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"ë‹¤ìŒ RAG ì‹œìŠ¤í…œì˜ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "ì •ë‹µ(ì°¸ì¡°): {reference}\n",
    "RAG ë‹µë³€: {answer}\n",
    "ê²€ìƒ‰ëœ ë¬¸ì„œ: {context[:500]}...\n",
    "\n",
    "ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ 1-5ì  í‰ê°€ (JSONìœ¼ë¡œë§Œ ì‘ë‹µ):\n",
    "- faithfulness: ë‹µë³€ì´ ê²€ìƒ‰ ë¬¸ì„œì— ì¶©ì‹¤í•œê°€?\n",
    "- relevancy: ë‹µë³€ì´ ì§ˆë¬¸ì— ì ì ˆí•œê°€?\n",
    "-  correctness: ë‹µë³€ì´ ì •ë‹µê³¼ ì¼ì¹˜í•˜ëŠ”ê°€?\n",
    "\n",
    "{{\"faithfulness\": ì ìˆ˜, \"relevancy\": ì ìˆ˜, \"correctness\": ì ìˆ˜, \"comment\": \"í•œì¤„í‰\"}}\"\"\"\n",
    "        }]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "print(\"ğŸ“Š RAG í‰ê°€ ì§„í–‰ ì¤‘...\")\n",
    "results = []\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    q = row['user_input']\n",
    "    ref = row['reference']\n",
    "\n",
    "    # RAGë¡œ ë‹µë³€ ìƒì„±\n",
    "    rag_result = rag_chain.invoke([\"query\": q])\n",
    "    answer = rag_result['result']\n",
    "    context = \" \".join([doc.page_content for doc in rag_result['source_documents']])\n",
    "\n",
    "    # í‰ê°€\n",
    "    eval_result = simple_evalute(q, answer, ref, context)\n",
    "    print(f\"   ë¬¸ì œ {i+1} í‰ê°€ ì™„ë£Œ\")\n",
    "    results.append({\n",
    "        'question': q,\n",
    "        'answer': answer,\n",
    "        'evaluation': eval_result\n",
    "    })\n",
    "\n",
    "print(\"\\nâœ… í‰ê°€ ì™„ë£Œ!\")\n",
    "for r in results:\n",
    "    print(f\"\\nğŸ“ Q: {r['question'][:50]}...\")\n",
    "    print(f\"   í‰ê°€: {r['evaluation']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9caeb2b",
   "metadata": {},
   "source": [
    "#### ğŸ” ê²°ê³¼ ë¶„ì„ ë° ê°œì„  ë°©í–¥\n",
    "\n",
    "|**ë¬¸ì œ ìƒí™©**|**ë‚®ì€ ë©”íŠ¸ë¦­**|**ê°œì„  ë°©í–¥**|\n",
    "|----|----|----|\n",
    "|í• ë£¨ì‹œë„¤ì´ì…˜ ë°œìƒ|Faithfulness â†“|í”„ë¡¬í”„íŠ¸ì— \"Contextì— ì—†ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë‹µë³€\" ì§€ì‹œ ì¶”ê°€|\n",
    "|ì—‰ëš±í•œ ë‹µë³€|Answer Relevancy â†“|ì¿¼ë¦¬ ì¬ì‘ì„±(Query Rewrite) ë„ì…|\n",
    "|ê´€ë ¨ ë¬¸ì„œ ëˆ„ë½|Context Recall â†“|Retriever kê°’ ì¦ê°€, Hybrid ê°€ì¤‘ì¹˜ ì¡°ì •|\n",
    "|ë…¸ì´ì¦ˆ ë¬¸ì„œ ìƒìœ„|Context Precision â†“|Reranker ëª¨ë¸ êµì²´, Fine-tuning|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ca068",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02662444",
   "metadata": {},
   "source": [
    "#### 9. ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¹„êµ ì‹¤í— (Naive vs Advanced)\n",
    "ì§€ê¸ˆê¹Œì§€ êµ¬ì¶•í•œ ë‹¤ì–‘í•œ íŒŒì´í”„ë¼ì¸ì˜ ì„±ëŠ¥ì„ í•œëˆˆì— ë¹„êµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9523fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ì–‘í•œ Retriever íŒŒì´í”„ë¼ì¸ ì •ì˜\n",
    "pipelines = {\n",
    "    \"1. BM25 Only (Baseline)\": bm25_retriever,\n",
    "    \"2. Vector Only (Naive RAG)\": vector_retriever,\n",
    "    \"3. Hybrid (BM25 + Vector)\": hybrid_retriever,\n",
    "    \"4. Hybrid + Reranker (Advanced)\": reranker_retriever\n",
    "}\n",
    "\n",
    "test_query = \"ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ê³¼ í™œìš© ì‚¬ë¡€ì— ëŒ€í•´ ì•Œë ¤ì¤˜\"\n",
    "\n",
    "print(f\"ğŸ” í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: '{test_query}'\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for name, retriever in pipelines.items():\n",
    "    docs = retriever.invoke(test_query)\n",
    "\n",
    "    print(f\"\\nğŸ“Œ {name}\")\n",
    "    print(f\"   ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}\")\n",
    "\n",
    "    if docs:\n",
    "        print(f\"   Top-1 ë¯¸ë¦¬ë³´ê¸°: {docs[0].page_content[:60]}...\")\n",
    "        comparison_results.append({\n",
    "            \"Pipeline\": name,\n",
    "            \"ë¬¸ì„œ ìˆ˜\": len(docs),\n",
    "            \"Top-1 ì¶œì²˜\": docs[0].metadata.get('source', 'unknown')\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nğŸ“Š íŒŒì´í”„ë¼ì¸ ë¹„êµ ìš”ì•½:\")\n",
    "display(pd.DataFrame(comparison_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57153024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ì–‘í•œ Retriever íŒŒì´í”„ë¼ì¸ ì •ì˜ ë° LLM as Judge í‰ê°€\n",
    "prpilines = {\n",
    "    \"1. BM25 Only (Baseline)\": bm25_retriever,\n",
    "    \"2. Vector Only (Naive RAG)\": vector_retriever,\n",
    "    \"3. Hybrid (BM25 + Vector)\": hybrid_retriever,\n",
    "    \"4. Hybrid + Reranker (Advanced)\": rerank_retriever\n",
    "}\n",
    "\n",
    "test_query = \"ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ê³¼ í™œìš© ì‚¬ë¡€ì— ëŒ€í•´ ì•Œë ¤ì¤˜\"\n",
    "\n",
    "print(f\"ğŸ” í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: '{test_query}'\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_results = []\n",
    "llm_eval_results = []\n",
    "\n",
    "for name, retriever in pipelines.items():\n",
    "    docs = retriever.invoke(test_query)\n",
    "    answer = \"\"\n",
    "    context = \"\"\n",
    "    if docs:\n",
    "        # RAG ë‹µë³€ ìƒì„± (ì˜ˆì‹œ: ì²« ë¬¸ì„œ ë‚´ìš© í™œìš©)\n",
    "        context = \" \".join([doc.page_content for doc in docs])\n",
    "        # ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì—°ê²°\n",
    "        answer = docs[0].page_content[:300]\n",
    "    else:\n",
    "        answer = \"ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\"\n",
    "        context = \"\"\n",
    "    print(f\"\\nğŸ“Œ {name}\")\n",
    "    print(f\"   ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}\")\n",
    "    if docs:\n",
    "        print(f\"   Top-1 ë¯¸ë¦¬ë³´ê¸°: {docs[0].page_content[:60]}...\")\n",
    "        comparison_results.append({\n",
    "            \"Pipeline\": name,\n",
    "            \"ë¬¸ì„œ ìˆ˜\": len(docs),\n",
    "            \"Top-1 ì¶œì²˜\": docs[0].metadata.get('source', 'unknown')\n",
    "        })\n",
    "    # LLM as Judge í‰ê°€\n",
    "    eval_result = simple_evaluate(test_query, answer, \"(ì°¸ì¡° ì—†ì‘)\", context)\n",
    "    print(f\"   LLM í‰ê°€: {eval_result}\")\n",
    "    llm_eval_results.append({\n",
    "        \"Pipeline\": name,\n",
    "        \"LLM í‰ê°€\": eval_result\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nğŸ“Š íŒŒì´í”„ë¼ì¸ ë¹„êµ ìš”ì•½:\")\n",
    "display(pd.DataFrame(comparison_results))\n",
    "print(\"\\nğŸ¤– LLM as Judge í‰ê°€ ìš”ì•½:\")\n",
    "display(pd.DataFrame(llm_eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a665d9c0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48ec4c",
   "metadata": {},
   "source": [
    "## ğŸ‰ ê²°ë¡  ë° ê³ ì°°\n",
    "#### ì˜¤ëŠ˜ ë°°ìš´ í•µì‹¬ ê°œë…\n",
    "1. **ê²€ìƒ‰ ë°©ì‹ì˜ ì§„í™”**\n",
    "- BM25 (í‚¤ì›Œë“œ) â†’ Vector (ì˜ë¯¸) â†’ Hybrid (ê²°í•©) â†’ Rerank (ì •ë°€í™”)\n",
    "2. **Query Decomposition**\n",
    "- ë³µì¡í•œ ì§ˆë¬¸ì„ ë¶„í•´í•˜ì—¬ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ\n",
    "- PPTì˜ \"ì‚¼ì„±ì „ì vs í•˜ì´ë‹‰ìŠ¤\" ì˜ˆì‹œì²˜ëŸ¼ ì‹¤ë¬´ì—ì„œ ìì£¼ ì‚¬ìš©\n",
    "3. **2-Stage Retrieval**\n",
    "- Bi-Encoderë¡œ ë¹ ë¥´ê²Œ í›„ë³´ ì¶”ì¶œ â†’ Cross-Encoderë¡œ ì •ë°€ ì¬ì •ë ¬\n",
    "4. **RAGAS í‰ê°€**\n",
    "- Faithfulness: í• ë£¨ì‹œë„¤ì´ì…˜ ì²´í¬\n",
    "- Answer Relevancy: ì§ˆë¬¸ ì˜ë„ ë¶€í•©ë„\n",
    "- Context Recall/Precision: ê²€ìƒ‰ í’ˆì§ˆ\n",
    "\n",
    "#### PPTì˜ í•µì‹¬ ë©”ì‹œì§€\n",
    "```\n",
    "\"ì—”ì§€ë‹ˆì–´ë§ì— ë¬´ì¡°ê±´ì ì¸ í•´ë‹µì€ ì—†ì§€ë§Œ, ëª©ì ì— ë§ëŠ” ìµœì í™”ëŠ” ì¡´ì¬í•©ë‹ˆë‹¤.\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
