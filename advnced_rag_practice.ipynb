{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4861bd20",
   "metadata": {},
   "source": [
    "## ëŒ€ìš©ëŸ‰ ë¹„ì •í˜• ë°ì´í„° ê¸°ë°˜ Advanced RAG êµ¬ì¶• ë° í‰ê°€\n",
    "#### ê°•ì˜ ëª©í‘œ\n",
    "1. **Real-World Data Handling**: ë‚˜ë¬´ìœ„í‚¤(êµ¬ì–´ì²´/ì§€ì‹) FinePDFs(ë¬¸ì–´ì²´/ì „ë¬¸ë¬¸ì„œ)ê°€ ì„ì¸ ë‘ê°œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "2. **Beyond Keyword Search**: ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­(BM25)ê³¼ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰(Vector Search)ì˜ ê²°ì •ì  ì°¨ì´ë¥¼ ì²´ê°í•©ë‹ˆë‹¤.\n",
    "3. **Hybrid Search**: BM25ì™€ Vector Searchë¥¼ ê²°í•©í•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
    "4. **Advanced Pipeline**: Retriever + Reranker êµ¬ì¡°ë¥¼ í†µí•´ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ê·¹ëŒ€í™”í•˜ëŠ” ê¸°ë²•ì„ ìµí™ë‹ˆë‹¤.\n",
    "5. **Query Decomposition**: ë³µì¡í•œ ì§ˆì˜ë¥¼ ë¶„í•´í•˜ì—¬ ë” ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì–»ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "6. **Data-Driven Evalution**: ì •ë‹µì§€ê°€ ì—†ëŠ” ìƒí™©ì—ì„œ LLMì„ ì´ìš©í•´ *í•©ì„± ë°ì´í„°ì…‹(Synthetic Testset)*ì„ ë§Œë“¤ê³  í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "#### ì‚¬ìš© ëª¨ë¸ ë° ë°ì´í„°\n",
    "- **LLM**: gpt-5-mini (High Performance & Low Cost)\n",
    "- **Data**: heegyu/namuwiki (General Knowledge) + HuggingFaceFW/finepdfs-edu (Domain Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4f814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (Jupyter í™˜ê²½ ê¶Œì¥ ë°©ì‹)\n",
    "\n",
    "# ë²„ì „ì„ ëª…ì‹œí•˜ì—¬ í˜¸í™˜ì„± ë¬¸ì œ ë°©ì§€\n",
    "\n",
    "%pip install -q \\\n",
    "    langchain==0.3.14 \\\n",
    "    langchain-openai==0.2.14 \\\n",
    "    langchain-huggingface==0.1.2 \\\n",
    "    langchain-community==0.3.14 \\\n",
    "    ragas==0.2.10 \\\n",
    "    datasets \\\n",
    "    sentence-transformers \\\n",
    "    tiktoken \\\n",
    "    rank_bm25 \\\n",
    "    pandas \\\n",
    "    faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0b2324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# API_KEY ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d7850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print API key\n",
    "# print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY'][:-15]}\" + \"*\" * 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbcaef5",
   "metadata": {},
   "source": [
    "## 1. Data Loading: 'í˜„ì‹¤ì ì¸' ë°ì´í„° ë¯¹ì‹±(Mixing)\n",
    "í˜„ì‹¤ì—ëŠ” ê¹”ë”í•˜ê²Œ ì •ì œëœ ë°ì´í„°ë§Œ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. **ì§€ì‹ ë°±ê³¼(Wiki)** ìŠ¤íƒ€ì¼ê³¼ **ë³´ê³ ì„œ(PDF)** ìŠ¤íƒ€ì¼ì˜ í…ìŠ¤íŠ¸ê°€ ì„ì—¬ì„œ, ë‚œì´ë„ê°€ ë†’ì€ í†µí•© ê²€ìƒ‰ í™˜ê²½ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5681a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘...\n",
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ 200ê°œ ë¬¸ì„œ\n",
      "   - Wiki ì˜ˆì‹œ(ì´ 100ê°œ): [ì¶œì²˜: ë‚˜ë¬´ìœ„í‚¤] ì œëª©: !\n",
      "\n",
      "#redirect ëŠë‚Œí‘œ\n",
      "...\n",
      "   - PDF ì˜ˆì‹œ(ì´ 100ê°œ): ì´í•´ë„ í…ŒìŠ¤íŠ¸\n",
      "\n",
      "íƒ€ì…ã†ì œì¡°ë²•\n",
      "\n",
      "Q1 ì‚¬ì¼€ëŠ” ë¬´ì—‡ìœ¼ë¡œ ì œì¡°ë˜ëŠ”ê°€?\n",
      "\n",
      "a) ì‚¬ê³¼\n",
      "b) ìŒ€\n",
      "c) ë³´ë¦¬\n",
      "d) ì½©\n",
      "\n",
      "Q2 ì¼ë³¸ì—ì„œ ì‚¬ì¼€ë¥¼ ì œì¡°í•˜ê³  ìˆëŠ” ...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "print(\"ğŸ“¥ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘...\")\n",
    "\n",
    "raw_docs = []\n",
    "\n",
    "# [Source A] ë‚˜ë¬´ìœ„í‚¤ (General Knowledge)\n",
    "# íŠ¹ì§•: êµ¬ì–´ì²´, ë‹¤ì–‘í•œ ì£¼ì œ, ë©”íƒ€ë°ì´í„°ì— ì œëª© í¬í•¨\n",
    "wiki_stream = load_dataset(\"heegyu/namuwiki\", split=\"train\", streaming=True)\n",
    "for idx, data in enumerate(wiki_stream):\n",
    "    if idx >= 100: break  # ì‹¤ìŠµ ì†ë„ë¥¼ ìœ„í•´ 100ê°œë§Œ ì‚¬ìš©, Memory & Computation ì—¬ìœ ê°€ ìˆë‹¤ë©´ ì „ë¶€ ì¨ë³´ê¸°\n",
    "    # print(f\"[{idx+1}/100] {data}\")\n",
    "    content = f\"[ì¶œì²˜: ë‚˜ë¬´ìœ„í‚¤] ì œëª©: {data['title']}\\n\\n{data['text']}\"\n",
    "    raw_docs.append(Document(page_content=content, metadata={\"source\": \"namuwiki\", \"title\": data['title']}))\n",
    "\n",
    "length_of_wiki = len(raw_docs)\n",
    "\n",
    "# for i, doc in enumerate(raw_docs):\n",
    "#     print(f\"[{i+1}/10] {doc}\")\n",
    "\n",
    "# [Source B] FinePDFs-Edu (Domain Documents)\n",
    "# íŠ¹ì§•: ë¬¸ì–´ì²´, ì „ë¬¸ìš©ì–´, ì„œì‹(Header/Footer) ë…¸ì´ì¦ˆ ì¡´ì¬\n",
    "pdf_stream = load_dataset(\"HuggingFaceFW/finepdfs-edu\", \"kor_Hang\", split=\"train\", streaming=True)\n",
    "for idx, data in enumerate(pdf_stream):\n",
    "    if idx >= 100: break\n",
    "    # PDFëŠ” ì œëª©ì´ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš°ê°€ ë§ì•„ URLì„ ë©”íƒ€ë°ì´í„°ë¡œ ì‚¬ìš©\n",
    "    raw_docs.append(Document(page_content=data['text'], metadata={\"source\": \"finepdf\", \"url\": data['url']}))\n",
    "\n",
    "length_of_pdf = len(raw_docs) - length_of_wiki\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {len(raw_docs)}ê°œ ë¬¸ì„œ\")\n",
    "print(f\"   - Wiki ì˜ˆì‹œ(ì´ {length_of_wiki}ê°œ): {raw_docs[0].page_content[:80]}...\")\n",
    "print(f\"   - PDF ì˜ˆì‹œ(ì´ {length_of_pdf}ê°œ): {raw_docs[length_of_wiki].page_content[:80]}...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d49fc6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2587974",
   "metadata": {},
   "source": [
    "## 2. Advanced Chunking Strategy\n",
    "PPTì—ì„œ ê°•ì¡°í•œ **Chunking** ì „ëµì…ë‹ˆë‹¤.\n",
    "- **Attention Dilution ë°©ì§€**: ë„ˆë¬´ ê¸¸ë©´ LLMì´ í•µì‹¬ì„ ë†“ì¹©ë‹ˆë‹¤.\n",
    "- **Context Overlap**: ë¬¸ë§¥ì´ ëŠê¸°ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ Chunk_overlapì„ ë‘¡ë‹ˆë‹¤.\n",
    "- **Separators**: ë¬¸ë‹¨(\\n\\n) â†’ ì¤„ë°”ê¿ˆ(\\n) â†’ ë¬¸ì¥(.) ìˆœì„œë¡œ ì˜ë¯¸ ë‹¨ìœ„ë¥¼ ë³´ì¡´í•˜ë©° ìë¦…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9573c363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ ì²­í‚¹ ê²°ê³¼: 200ê°œ ë¬¸ì„œ â†’ 7641ê°œ ì²­í¬ë¡œ ë¶„í• ë¨\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PPT ì‹¤ë¬´ íŒ ë°˜ì˜: ì˜ë¯¸ ë‹¨ìœ„ ë³´ì¡´ì„ ìœ„í•œ ê³„ì¸µì  Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,  # ê²€ìƒ‰ì— ì ì ˆí•œ í¬ê¸° (í† í° ê¸°ì¤€ ì•„ë‹˜, ê¸€ì ìˆ˜ ê¸°ì¤€)\n",
    "    chunk_overlap=100,  # ì•ë’¤ ë¬¸ë§¥ ì—°ê²°ì„ ìœ„í•œ ì˜¤ë²„ë©\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # ì˜ë¯¸ ë‹¨ìœ„ ìš°ì„  ìˆœìœ„\n",
    ")\n",
    "\n",
    "splitted_docs = text_splitter.split_documents(raw_docs)\n",
    "print(f\"âœ‚ï¸ ì²­í‚¹ ê²°ê³¼: {len(raw_docs)}ê°œ ë¬¸ì„œ â†’ {len(splitted_docs)}ê°œ ì²­í¬ë¡œ ë¶„í• ë¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a613e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871fb8fe",
   "metadata": {},
   "source": [
    "## 3. ê²€ìƒ‰ ì—”ì§„ êµ¬ì¶•: BM25, Vector, Hybrid\n",
    "ì„¸ê°€ì§€ ê²€ìƒ‰ ë°©ì‹ì„ êµ¬ì¶•í•˜ê³  ë¹„êµí•©ë‹ˆë‹¤.\n",
    "\n",
    "|ë°©ì‹|íŠ¹ì§•|ì¥ì |ë‹¨ì |\n",
    "|----|----|----|----|\n",
    "|**BM25**|í‚¤ì›Œë“œ ë§¤ì¹­|ì •í™•í•œ ìš©ì–´ ê²€ìƒ‰ì— ê°•í•¨|ë™ì˜ì–´/ìœ ì‚¬ì–´ ì¸ì‹ ë¶ˆê°€|\n",
    "|**Vector**|ì˜ë¯¸ ê¸°ë°˜|ë¬¸ë§¥ì  ìœ ì‚¬ì„± íŒŒì•…|íŠ¹ì • í‚¤ì›Œë“œ ê²€ìƒ‰ì— ì•½í•¨|\n",
    "|**Hybrid**|BM25 + Vector ê²°í•©|ë‘ ì¥ì  ê²°í•©|ê°€ì¤‘ì¹˜ íŠœë‹ í•„ìš”|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e460837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BM25 & Vector(FAISS) ê²€ìƒ‰ ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 1. BM25 Retriever êµ¬ì¶•(í‚¤ì›Œë“œ ê¸°ë°˜)\n",
    "bm25_retriever = BM25Retriever.from_documents(splitted_docs)\n",
    "bm25_retriever.k = 5  # í›„ë³´êµ°ì„ ë„‰ë„‰í•˜ê²Œ\n",
    "\n",
    "# 2. Vector Store êµ¬ì¶• (ì˜ë¯¸ ê¸°ë°˜, FAISS ì‚¬ìš©)\n",
    "# OpenAI Embedding ì‚¬ìš©\n",
    "openai_embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splitted_docs,\n",
    "    embedding=openai_embedding\n",
    ")\n",
    "vector_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(\"âœ… BM25 & Vector(FAISS) ê²€ìƒ‰ ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666e3ed",
   "metadata": {},
   "source": [
    "#### 3.1 ğŸ†• Hybrid Search êµ¬í˜„ (PPT 23-24 ìŠ¬ë¼ì´ë“œ)\n",
    "**Î»â€¢BM25 + (1-Î»)â€¢Vector** í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì…ë‹ˆë‹¤.\n",
    "```\n",
    "ìµœì¢… ìŠ¤ì½”ì–´ = Î± * BM25_score + (1 - Î±) * Vector_score\n",
    "```\n",
    "LangChainì˜ EnsembleRetrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ RRF(Reciprocal Rank Fusion) ë°©ì‹ìœ¼ë¡œ ê²°í•©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a5b9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hybrid Search ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!\n",
      "   - BM25 ê°€ì¤‘ì¹˜: 0.4 (í‚¤ì›Œë“œ ë§¤ì¹­)\n",
      "   - Vector ê°€ì¤‘ì¹˜: 0.6 (ì˜ë¯¸ ê¸°ë°˜)\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "# Hybrid Retriever: BM25(í‚¤ì›Œë“œ) + Vector(ì˜ë¯¸) ê²°í•©\n",
    "# weights: [BM25 ê°€ì¤‘ì¹˜, Vector ê°€ì¤‘ì¹˜] - í•©ì´ 1ì´ ë  í•„ìš”ëŠ” ì—†ìŒ\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.4, 0.6]  # Vectorì— ì•½ê°„ ë” ê°€ì¤‘ì¹˜ (ì‚¬ì „ ì •ì˜ëœ ì§ˆë¬¸ Coverageì— ë”°ë¼ ì¡°ì •)\n",
    ")\n",
    "\n",
    "print(\"âœ… Hybrid Search ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"   - BM25 ê°€ì¤‘ì¹˜: 0.4 (í‚¤ì›Œë“œ ë§¤ì¹­)\")\n",
    "print(\"   - Vector ê°€ì¤‘ì¹˜: 0.6 (ì˜ë¯¸ ê¸°ë°˜)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45bcf72",
   "metadata": {},
   "source": [
    "#### 3.2 ê²€ìƒ‰ ë°©ì‹ ë¹„êµ ì‹¤í—˜\n",
    "ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ ì„¸ê°€ì§€ ê²€ìƒ‰ ë°©ì‹ì˜ ê²°ê³¼ë¥¼ ë¹„êµí•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e41d440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì§ˆë¬¸: 'í”„ë¦°í„° ì¶”ì²œ'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Œ [BM25 (í‚¤ì›Œë“œ)] ìƒìœ„ 3ê°œ ê²°ê³¼:\n",
      "----------------------------------------\n",
      "   1. [finepdf] ì¸ì‡„ - ë¡œì»¬ í”„ë¦°í„° / ë„¤íŠ¸ì›Œí¬ í”„ë¦°í„° ì„¤ì¹˜, ì—¬ëŸ¬ëŒ€ í”„ë¦°í„° ì„¤ì¹˜ ê°€ëŠ¥; ê¸°ë³¸í”„ë¦°í„°ëŠ” ëŒ€ëŸ‰ì„¤ì¹˜ (ë¡œì»¬ ë„¤íŠ¸ì›Œí¬ë¡œ ì„¤ì¹˜í•œ í”„ë¦°í„° ëª¨ë‘ ê¸°ë³¸í”„ë¦°í„°ë¡œ ì„¤ì • ê°€ëŠ¥)   - ë¬¸ì„œì¸ì‡„: í•´...\n",
      "   2. [finepdf] í”„ë¦°í„° ê³µìœ  - ì‹œì¥ - ì ì¬ì—… í”„ë¦°í„° - ê³µìœ í•œ í”„ë¦°í„° - ì†ì„± - ê³µìœ  - 'ì–´í”Œë¦¬ì¼€ì…˜ ê³µìœ '   - ì‹œì¥ - ì œì–´íŒ - ë„¤íŠ¸ì›Œí¬ ë° ê³µìœ  ì„¼í„° - ê³µìœ  ì„¤ì • ë³€ê²½ - ì„œë¹„ìŠ¤ ...\n",
      "   3. [finepdf] ìˆ˜ì„ í™”ì‹œë‚­ì†¡ ë™ì•„ë¦¬  ì½”ë¡œë‚˜19ì˜ ì¥ê¸°í™”ë¡œ í•¨ê»˜í•˜ëŠ” ë™ì•„ë¦¬ ëª¨ì„, ì°¾ì•„ê°€ëŠ” ë´‰ì‚¬ í™œë™ì´ ì–´ë ¤ì›Œì§„ í™˜ê²½ ì†ì—ì„œ ë‹¤ì–‘í•˜ê³  í˜ì‹ ì ì¸ ì˜¨ë¼ì¸ êµìœ¡ í™œë™ì„ ê°œë°œí•˜ì—¬ ì‹œë‚­ì†¡ì˜ ì˜ë¯¸ì™€ ì¦ê±°ì›€ì´...\n",
      "\n",
      "ğŸ“Œ [Vector (ì˜ë¯¸)] ìƒìœ„ 3ê°œ ê²°ê³¼:\n",
      "----------------------------------------\n",
      "   1. [finepdf] í”„ë¦°í„° ê³µìœ  - ì‹œì¥ - ì ì¬ì—… í”„ë¦°í„° - ê³µìœ í•œ í”„ë¦°í„° - ì†ì„± - ê³µìœ  - 'ì–´í”Œë¦¬ì¼€ì…˜ ê³µìœ '   - ì‹œì¥ - ì œì–´íŒ - ë„¤íŠ¸ì›Œí¬ ë° ê³µìœ  ì„¼í„° - ê³µìœ  ì„¤ì • ë³€ê²½ - ì„œë¹„ìŠ¤ ...\n",
      "   2. [finepdf] ìì£¼ì“°ì´ê¸°  ì»´í“¨í„° â†’ ë“œë¼ì´ë¸Œ â†’ ì†ì„±, ë””ìŠ¤í¬ì •ë¦¬, â†’ ê³µê°„í™•ë³´ê°œë³„.. PC ê´€ë¦¬ êµ¬ë¶„ í•„ìš” ë ˆì§€ìŠ¤íŠ¸ë¦¬ â†’ ë¶€íŒ…ë§Œ ì•„ë‹ˆë¼ ìš´ì˜ì´ í•„ìš”í•œ ì •ë³´ê°€ìˆ í”„ë¦°íŒ…ê¸°ëŠ” ìœˆë„ìš°ì—ì„œ ì´ìš©.  ...\n",
      "   3. [finepdf] ë³´ì¡°í”„ë¡œê·¸ë¨ - ë©”ëª¨ì¥, ì›Œë“œí”„ë ˆìŠ¤ í”„ë¡œê·¸ë¨ ë“± - ì•± í”„ë¡œê·¸ë¨ (ë„¤ì´ë²„, ë§ˆì´í¬ë¡œì†Œí”„íŠ¸) - ê¸°íƒ€ ì›Œë“œí”„ë ˆìŠ¤ (FTP, ë°”ì´ë„ˆìŠ¤ í”„ë¡œê·¸ë¨, ë·°ì–´ í”„ë¡œê·¸ë¨)  ì§ˆë¬¸  ìš”ì•½ ìŠ¤í”Œ -...\n",
      "\n",
      "ğŸ“Œ [Hybrid (ê²°í•©)] ìƒìœ„ 3ê°œ ê²°ê³¼:\n",
      "----------------------------------------\n",
      "   1. [finepdf] í”„ë¦°í„° ê³µìœ  - ì‹œì¥ - ì ì¬ì—… í”„ë¦°í„° - ê³µìœ í•œ í”„ë¦°í„° - ì†ì„± - ê³µìœ  - 'ì–´í”Œë¦¬ì¼€ì…˜ ê³µìœ '   - ì‹œì¥ - ì œì–´íŒ - ë„¤íŠ¸ì›Œí¬ ë° ê³µìœ  ì„¼í„° - ê³µìœ  ì„¤ì • ë³€ê²½ - ì„œë¹„ìŠ¤ ...\n",
      "   2. [finepdf] ê³¼ëª©ëª…: ì»´í“¨í„° í™œìš©ëŠ¥ë ¥ í–¥ê¸° í•™ìŠµì£¼ì œ: ì»´í“¨í„° ì—´ë°˜ í•™ìŠµëª©í‘œ: ìš´ì˜ì²´ì œ  í•µì‹¬  ìŠ¤í”Œ - ì¸ì‡„í•œ ë‚´ìš©ì„ í•˜ë“œë””ìŠ¤í¬ì™€ ê°™ì€ ë³´ì¡° ê¸°ì–µ ì¥ì¹˜ì— ì„ì‹œ ì €ì¥í•œ í›„ í”„ë¦°í„°ë¡œ ì „ì†¡í•˜ê¸°ë¡œ -...\n",
      "   3. [finepdf] ìì£¼ì“°ì´ê¸°  ì»´í“¨í„° â†’ ë“œë¼ì´ë¸Œ â†’ ì†ì„±, ë””ìŠ¤í¬ì •ë¦¬, â†’ ê³µê°„í™•ë³´ê°œë³„.. PC ê´€ë¦¬ êµ¬ë¶„ í•„ìš” ë ˆì§€ìŠ¤íŠ¸ë¦¬ â†’ ë¶€íŒ…ë§Œ ì•„ë‹ˆë¼ ìš´ì˜ì´ í•„ìš”í•œ ì •ë³´ê°€ìˆ í”„ë¦°íŒ…ê¸°ëŠ” ìœˆë„ìš°ì—ì„œ ì´ìš©.  ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_retrievers(query: str):\n",
    "    \"\"\"ì„¸ê°€ì§€ ê²€ìƒ‰ ë°©ì‹ ê²°ê³¼ ë¹„êµ\"\"\"\n",
    "    print(f\"ğŸ” ì§ˆë¬¸: '{query}'\\n\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    results = {\n",
    "        \"BM25 (í‚¤ì›Œë“œ)\": bm25_retriever.invoke(query),\n",
    "        \"Vector (ì˜ë¯¸)\": vector_retriever.invoke(query),\n",
    "        \"Hybrid (ê²°í•©)\": hybrid_retriever.invoke(query)\n",
    "    }\n",
    "\n",
    "    for method, docs in results.items():\n",
    "        print(f\"\\nğŸ“Œ [{method}] ìƒìœ„ 3ê°œ ê²°ê³¼:\")\n",
    "        print(\"-\" * 40)\n",
    "        for i, doc in enumerate(docs[:3], 1):\n",
    "            source = doc.metadata.get('source', 'unknown')\n",
    "            preview = doc.page_content[:100].replace('\\n', ' ')\n",
    "            print(f\"   {i}. [{source}] {preview}...\")\n",
    "        if not docs:\n",
    "            print(\"   â†’ ê²°ê³¼ ì—†ìŒ\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ 1: ì˜ë¯¸ë¡ ì  ì§ˆë¬¸(Vectorê°€ ìœ ë¦¬)\n",
    "results1 = compare_retrievers(\"í”„ë¦°í„° ì¶”ì²œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9adf9847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì§ˆë¬¸: 'ëŒ€í•œë¯¼êµ­ í—Œë²• ì œ1ì¡°'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Œ [BM25 (í‚¤ì›Œë“œ)] ìƒìœ„ 3ê°œ ê²°ê³¼:\n",
      "----------------------------------------\n",
      "   1. [finepdf] â€˜IMFâ€™ì™€ â€˜ë²¤ì²˜ê¸°ì—…â€™ê³¼ ëˆˆë¨¼ ë‚˜ë¼ ëˆ ì´ëŒ€ë¡œ ................................................................. 11 4ì›” 1...\n",
      "   2. [finepdf] ì¤‘ì†Œê¸°ì—…ì„ ìœ¡ì„±ì‹œì¼œì„œ ì¼ìë¦¬ë¥¼ ëŠ˜ë¦¬ê³  ìš°ë¦¬ ê²½ì œë¥¼ ë°œì „ì‹œí‚¤ê² ë‹¤ëŠ” ì·¨ì§€ëŠ” ê³µê°í•˜ì§€ë§Œ â€˜ë²¤ì²˜â€™ë€ ì™¸êµ­ë§ì„ ëŒ€í•œë¯¼êµ­ ì¤‘ì•™ë¶€ì²˜ ì´ë¦„ì— ë“¤ì–´ê°€ëŠ” ê²ƒì€ ê°•ë ¥í•˜ê²Œ ë°˜ëŒ€í•©ë‹ˆë‹¤.  ê·¸ ê¹Œë‹­ì€ ìš°ë¦¬...\n",
      "   3. [namuwiki] ëŒ€í•œë¯¼êµ­ êµ­êµ°ì—ì„œë„ M1911ì„ ì œì‹ìœ¼ë¡œ ì±„ìš© í–ˆì—ˆìœ¼ë‚˜ [[K5 ê¶Œì´]]ìœ¼ë¡œ ì „ë¶€ êµì²´í–ˆë‹¤. == ê´€ë ¨ ë¬¸ì„œ ==  * [[ë¬´ê¸° ê´€ë ¨ ì •ë³´]]  * [[ê°ì¢… íƒ„ì•½ í¬íƒ„ êµ¬ê²½ ì¼ëŒ]...\n",
      "\n",
      "ğŸ“Œ [Vector (ì˜ë¯¸)] ìƒìœ„ 3ê°œ ê²°ê³¼:\n",
      "----------------------------------------\n",
      "   1. [finepdf] â‘¥ ì§ì ‘ì›ì¸ì€ ì¸ì ì›ì¸ê³¼ ë¬¼ì ì›ì¸ìœ¼ë¡œ êµ¬ë³„ëœë‹¤.  â‘¦ ì§ì ‘ì›ì¸(1ì°¨ì›ì¸)ì—ëŠ” ê·¸ê²ƒì˜ ì¡´ì¬ ì´ìœ ê°€ ìˆë‹¤. ì´ê²ƒì„ 2ì°¨ì›ì¸ ì´ë¼ê³  í•œë‹¤.  â‘§ 2ì°¨ì›ì¸ ì´ì „ì—ëŠ” ê¸°ì´ˆì›ì¸ì´ ìˆë‹¤.  â‘¨...\n",
      "   2. [finepdf] 4 ê°€ì§€ ì›ì¹™...\n",
      "   3. [finepdf] ì²«ì§¸ë¡œ ì ìš©ëœ ë³‘ë²•ì€ 'ì •ë³´íšë“(æƒ…å ±ç²å¾—)ì˜ ì›ë¦¬'ì´ë‹¤. ì „ë¼ì¢Œìš°ìˆ˜ì˜ê³¼ ê²½ìƒìš°ìˆ˜ì˜ í•¨ëŒ€ë¥¼ í†µí•©í•œ ì´ìˆœì‹  í•¨ëŒ€ëŠ” í•œì‚°í•´ì „ì´ ë²Œì–´ì§€ê¸° í•˜ë£¨ ì „ì¸ ì„ì§„ë…„(1592 ë…„) 7 ì›” 6 ì¼ ë¯¸...\n",
      "\n",
      "ğŸ“Œ [Hybrid (ê²°í•©)] ìƒìœ„ 3ê°œ ê²°ê³¼:\n",
      "----------------------------------------\n",
      "   1. [finepdf] â‘¥ ì§ì ‘ì›ì¸ì€ ì¸ì ì›ì¸ê³¼ ë¬¼ì ì›ì¸ìœ¼ë¡œ êµ¬ë³„ëœë‹¤.  â‘¦ ì§ì ‘ì›ì¸(1ì°¨ì›ì¸)ì—ëŠ” ê·¸ê²ƒì˜ ì¡´ì¬ ì´ìœ ê°€ ìˆë‹¤. ì´ê²ƒì„ 2ì°¨ì›ì¸ ì´ë¼ê³  í•œë‹¤.  â‘§ 2ì°¨ì›ì¸ ì´ì „ì—ëŠ” ê¸°ì´ˆì›ì¸ì´ ìˆë‹¤.  â‘¨...\n",
      "   2. [finepdf] 4 ê°€ì§€ ì›ì¹™...\n",
      "   3. [finepdf] ì²«ì§¸ë¡œ ì ìš©ëœ ë³‘ë²•ì€ 'ì •ë³´íšë“(æƒ…å ±ç²å¾—)ì˜ ì›ë¦¬'ì´ë‹¤. ì „ë¼ì¢Œìš°ìˆ˜ì˜ê³¼ ê²½ìƒìš°ìˆ˜ì˜ í•¨ëŒ€ë¥¼ í†µí•©í•œ ì´ìˆœì‹  í•¨ëŒ€ëŠ” í•œì‚°í•´ì „ì´ ë²Œì–´ì§€ê¸° í•˜ë£¨ ì „ì¸ ì„ì§„ë…„(1592 ë…„) 7 ì›” 6 ì¼ ë¯¸...\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 2: íŠ¹ì • í‚¤ì›Œë“œ ì§ˆë¬¸ (BM25ê°€ ìœ ë¦¬)\n",
    "results2 = compare_retrievers(\"ëŒ€í•œë¯¼êµ­ í—Œë²• ì œ1ì¡°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6de62fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì§ˆë¬¸: 'ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ê³¼ ë¯¸ë˜ ì „ë§'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Œ [BM25 (í‚¤ì›Œë“œ)] ìƒìœ„ 3ê°œ ê²°ê³¼:\n",
      "----------------------------------------\n",
      "   1. [finepdf] ì„¤ë¬¸ì¡°ì‚¬ëŠ” ì–´ë–¤ ì£¼ì œë¥¼ ë‹¤ë£¨ë‚˜ìš”?  ì„¤ë¬¸ì¡°ì‚¬ëŠ” í•™ìƒë“¤ì´ í•™êµì—ì„œ ê²ªëŠ” ì›°ë¹™, ì°¸ì—¬ ë° ê²½í—˜ê³¼ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ì¸¡ë©´ë“¤ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤. ì§ˆë¬¸ì— í¬í•¨ë˜ëŠ” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:  íšŒë³µë ¥ ...\n",
      "   2. [finepdf] ê´€ë ¨í•œ ì •ì±…ë“¤ì„ ë‹¤ë£¬ë‹¤.  l í•œêµ­ì •ì¹˜íŠ¹ê°•(Korean Politics Seminar Study) í•œêµ­ì •ì¹˜ì˜ ê³¼ê±°ì™€ í˜„ì¬ë¥¼ ì¡°ëª…í•˜ê³  ì¸ì§€í•˜ë©°, ë¯¸ë˜ í•œêµ­ì •ì¹˜ì˜ ë°œì „ë°©í–¥ì„ ë…¼ì˜í•˜ê³  ...\n",
      "   3. [finepdf] ì´ëŸ° ì±…ì€ ì½ì§€ ë§™ì‹œë‹¤  ì´ì •ìš° ì´ì˜¤ë•í•™êµ í° ì„ ìƒë‹˜.  ì˜¤ë˜ëœ ë¯¸ë˜ ë¼ë‹¤í¬ë¡œë¶€í„°(ì—ì„œ) ë°°ìš´ë‹¤. í—¬ë ˆë‚˜ ë…¸ë¥´ë² ë¦¬-í˜¸ì§€ ë…¹ìƒ‰í‰ë¡  ì¶œíŒì‚¬, ê¹€ì¢…ì² / ê¹€íƒœì–¸ ì˜®ê¹€...\n",
      "\n",
      "ğŸ“Œ [Vector (ì˜ë¯¸)] ìƒìœ„ 3ê°œ ê²°ê³¼:\n",
      "----------------------------------------\n",
      "   1. [finepdf] . ì™œëƒí•˜ë©´ 'ì˜ë¯¸'ë‚˜ 'ëª©ì 'ì€ ì•„ë¬´ë¦¬ ì¸ê³µì§€ëŠ¥ì´ ë°œë‹¬í•œë‹¤ í•´ë„ ìë™í™” ë  ìˆ˜ ì—†ê³ , 'ì§„ ì‹¬' ë˜í•œ ë§ˆì°¬ê°€ì§€ ì´ê¸° ë•Œë¬¸ì´ë‹¤. ì €ìëŠ” ìš°ë¦¬ì—ê²Œ ì´ëŸ¬í•œ ëŠ¥ë ¥ì´ ìˆê¸°ì—, ê³µìƒê³¼í•™ì—ì„œ...\n",
      "   2. [finepdf] ë¬¼ë¡  ì´ëŸ¬í•œ ì–´ë‘ìš´ ì „ë§ì—ëŠ” ê·¸ëŸ´ë§Œí•œ ì´ìœ ê°€ ìˆë‹¤. ì‹¬ê°í•œ í™˜ê²½ ë³€í™”ì™€ ì‚¬íšŒì  ë¬¸ì œë“¤ì´ ë‚˜íƒ€ë‚˜ê³  ìˆë‹¤. íŠ¹íˆ ê¸°í›„ë³€í™”ì™€ ë¶ˆí‰ë“±, ì¸êµ¬ë³€í™”ê°€ íŠ¹ì§•ì ì´ë‹¤. ì´ëŸ¬í•œ í˜„ìƒë“¤ì— ì¸ê³µì§€ëŠ¥ê³¼ ...\n",
      "   3. [finepdf] (6) ì•„ì´ë“¤ì˜ ë¯¸ë˜ë¥¼ ìœ„í•œ ë””ì§€í„¸ í™œìš© ëŠ¥ë ¥ í–¥ìƒ ì§€ì›  í•™ìƒë“¤ì˜ ë””ì§€í„¸ ì—­ëŸ‰ ê°•í™” êµìœ¡ë„ í™•ëŒ€í•œë‹¤. ì´ˆì¤‘ê³  í•™ìƒë“¤ì—ê²Œ ë¯¼Â·ê´€ì˜ ìš°ìˆ˜ ì†Œí”„íŠ¸ì›¨ì–´, ì¸ê³µì§€ëŠ¥ ë“±ì˜ êµìœ¡ì„ ì œê³µí•˜ëŠ” ...\n",
      "\n",
      "ğŸ“Œ [Hybrid (ê²°í•©)] ìƒìœ„ 3ê°œ ê²°ê³¼:\n",
      "----------------------------------------\n",
      "   1. [finepdf] . ì™œëƒí•˜ë©´ 'ì˜ë¯¸'ë‚˜ 'ëª©ì 'ì€ ì•„ë¬´ë¦¬ ì¸ê³µì§€ëŠ¥ì´ ë°œë‹¬í•œë‹¤ í•´ë„ ìë™í™” ë  ìˆ˜ ì—†ê³ , 'ì§„ ì‹¬' ë˜í•œ ë§ˆì°¬ê°€ì§€ ì´ê¸° ë•Œë¬¸ì´ë‹¤. ì €ìëŠ” ìš°ë¦¬ì—ê²Œ ì´ëŸ¬í•œ ëŠ¥ë ¥ì´ ìˆê¸°ì—, ê³µìƒê³¼í•™ì—ì„œ...\n",
      "   2. [finepdf] ë¬¼ë¡  ì´ëŸ¬í•œ ì–´ë‘ìš´ ì „ë§ì—ëŠ” ê·¸ëŸ´ë§Œí•œ ì´ìœ ê°€ ìˆë‹¤. ì‹¬ê°í•œ í™˜ê²½ ë³€í™”ì™€ ì‚¬íšŒì  ë¬¸ì œë“¤ì´ ë‚˜íƒ€ë‚˜ê³  ìˆë‹¤. íŠ¹íˆ ê¸°í›„ë³€í™”ì™€ ë¶ˆí‰ë“±, ì¸êµ¬ë³€í™”ê°€ íŠ¹ì§•ì ì´ë‹¤. ì´ëŸ¬í•œ í˜„ìƒë“¤ì— ì¸ê³µì§€ëŠ¥ê³¼ ...\n",
      "   3. [finepdf] (6) ì•„ì´ë“¤ì˜ ë¯¸ë˜ë¥¼ ìœ„í•œ ë””ì§€í„¸ í™œìš© ëŠ¥ë ¥ í–¥ìƒ ì§€ì›  í•™ìƒë“¤ì˜ ë””ì§€í„¸ ì—­ëŸ‰ ê°•í™” êµìœ¡ë„ í™•ëŒ€í•œë‹¤. ì´ˆì¤‘ê³  í•™ìƒë“¤ì—ê²Œ ë¯¼Â·ê´€ì˜ ìš°ìˆ˜ ì†Œí”„íŠ¸ì›¨ì–´, ì¸ê³µì§€ëŠ¥ ë“±ì˜ êµìœ¡ì„ ì œê³µí•˜ëŠ” ...\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 3: ë³µí•©ì ì¸ ì§ˆë¬¸ (Hybridê°€ ìœ ë¦¬)\n",
    "results3 = compare_retrievers(\"ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ê³¼ ë¯¸ë˜ ì „ë§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2109de",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23377ba5",
   "metadata": {},
   "source": [
    "## 4. Advanced Pipeline: Reranker ë„ì…\n",
    "\"Rerankì˜ ê°œë…\"\n",
    "|ë‹¨ê³„|ëª¨ë¸|íŠ¹ì§•|\n",
    "|----|----|----|\n",
    "|**1ì°¨ ê²€ìƒ‰(Retriever)**|Bi-Encoder|ë¹ ë¦„, ëŒ€ëŸ‰ í›„ë³´ ì¶”ì¶œ|\n",
    "|**2ì°¨ ì •ë ¬(Reranker)**|Cross-Encoder|ëŠë¦¼, ì •ë°€í•œ ê´€ë ¨ì„± í‰ê°€|\n",
    "\n",
    "ì´ **2-Stage Retrieval** êµ¬ì¡°ê°€ í˜„ì—…ì—ì„œ ê°€ì¥ ë§ì´ ì“°ì´ëŠ” ê³ ì„±ëŠ¥ íŒ¨í„´ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be8fe4a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cohere'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# # --- ì˜¨í”„ë ˜ CrossEncoder Reranker (ì§ì ‘ ëª¨ë¸ ë¡œë“œ, ì°¸ê³ ìš©) ---\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# from sentence_transformers import CrossEncoder\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# from langchain.retrievers.document_compressors import BaseDocumentCompressor\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# # --- Cohere Rerank API ì§ì ‘ í˜¸ì¶œ ì»¤ìŠ¤í…€ Reranker ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcohere\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocuments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompressor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseDocumentCompressor\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cohere'"
     ]
    }
   ],
   "source": [
    "# # --- ì˜¨í”„ë ˜ CrossEncoder Reranker (ì§ì ‘ ëª¨ë¸ ë¡œë“œ, ì°¸ê³ ìš©) ---\n",
    "# from sentence_transformers import CrossEncoder\n",
    "# from langchain.retrievers.document_compressors import BaseDocumentCompressor\n",
    "# from langchain.schema import Document\n",
    "# from typing import List, Sequence\n",
    "# from pydantic import PrivateAttr\n",
    "\n",
    "# class CrossEncoderReranker(BaseDocumentCompressor):\n",
    "#     \"\"\"Cross-Encoder ê¸°ë°˜ Reranker (ì˜¨í”„ë ˜)\"\"\"\n",
    "#     model_name: str = \"BAAI/bge-reranker-base\"\n",
    "#     top_n: int = 3\n",
    "#     _model: CrossEncoder = PrivateAttr()\n",
    "\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self._model = CrossEncoder(self.model_name)\n",
    "    \n",
    "#     def compress_documents(self, documents: Sequence[Document], query: str, callbacks=None) -> List[Document]:\n",
    "#         if not documents:\n",
    "#             return []\n",
    "#         pairs = [(query, doc.page_content) for doc in documents]\n",
    "#         scores = self._model.predict(pairs)\n",
    "#         scored_docs = list(zip(scores, documents))\n",
    "#         scored_docs.sort(key=lambda x: x[0], reverse=True)\n",
    "#         return [doc for _, doc in scored_docs[:self.top_n]]\n",
    "    \n",
    "# # ì˜¨í”„ë ˜ Reranker ì‚¬ìš© ì˜ˆì‹œ (ì°¸ê³ ìš©)\n",
    "# reranker = CrossEncoderReranker(model_name=\"BAAI/bge-reranker-base\", top_n=3)\n",
    "\n",
    "# # --- Cohere Rerank API ì§ì ‘ í˜¸ì¶œ ì»¤ìŠ¤í…€ Reranker ---\n",
    "import cohere\n",
    "from langchain_core.documents.compressor import BaseDocumentCompressor\n",
    "from langchain.schema import Document\n",
    "from typing import List, Sequence\n",
    "from pydantic import PrivateAttr\n",
    "\n",
    "class CohereReranker(BaseDocumentCompressor):\n",
    "    cohere_api_key: str\n",
    "    top_n: int = 3\n",
    "    model: str = \"rerank-multilingual-v3.0\"\n",
    "    _client: cohere.Client = PrivateAttr()\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._client = cohere.Client(self.cohere_api_key)\n",
    "    \n",
    "    def compress_documents(self, documents: Sequence[Document], query: str, callbacks=None) -> List[Document]:\n",
    "        if not documents:\n",
    "            return []\n",
    "        docs_text = [doc.page_content for doc in documents]\n",
    "        results = self._client.rerank(\n",
    "            model=self.model,\n",
    "            query=query,\n",
    "            documents=docs_text,\n",
    "            top_n=self.top_n\n",
    "        )\n",
    "        return [documents[r.index] for r in results.results]\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "cohere_api_key = os.environ['COHERE_API_KEY']\n",
    "reranker = CohereReranker(cohere_api_key=cohere_api_key, top_n=3)\n",
    "\n",
    "# Base Retriever: Hybridì—ì„œ í›„ë³´êµ°ì„ ë„‰ë„‰í•˜ê²Œ(K=10) ê°€ì ¸ì˜´\n",
    "from  langchain.retrievers import EnsembleRetriever\n",
    "hybrid_retriever_wide = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        BM25Retriever.from_documents(splitted_docs, k=10),\n",
    "        vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "    ],\n",
    "    weights=[0.4, 0.6]\n",
    ")\n",
    "\n",
    "# ìµœì¢… Rerank Pipeline\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "rerank_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=reranker,\n",
    "    base_retriever=hybrid_retriever_wide\n",
    ")\n",
    "\n",
    "print(\"âœ… Advanced RAG Pipeline (Cohere Reranker, ì§ì ‘ í˜¸ì¶œ) êµ¬ì¶• ì™„ë£Œ!\")\n",
    "print(\"   - 1ì°¨: Hybrid Searchë¡œ 20ê°œ í›„ë³´ ì¶”ì¶œ\")\n",
    "print(\"   - 2ì°¨: Cohere Rerankë¡œ ìƒìœ„ 3ê°œ ì¬ì •ë ¬\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fce7c3",
   "metadata": {},
   "source": [
    "#### 5. ğŸ†• Query Decomposition (PPT 41-43 ìŠ¬ë¼ì´ë“œ)\n",
    "**ì¿¼ë¦¬ ë¶„í•´(Query Decomposition)** ê¸°ë²•\n",
    "\n",
    "ë³µì¡í•œ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê°œì˜ ë‹¨ìˆœí•œ í•˜ìœ„ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´í•˜ì—¬:\n",
    "1. ê° í•˜ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "2. ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±\n",
    "**ì˜ˆì‹œ**:\n",
    "- ì›ë³¸: \"ì‚¼ì„±ì „ìë‘ í•˜ì´ë‹‰ìŠ¤ ê°€ê²© ìƒìŠ¹ ìš”ì¸ ë¹„êµí•´ë´\"\n",
    "- ë¶„í•´:\n",
    "    - \"ì‚¼ì„±ì „ì ê°€ê²© ìƒìŠ¹ ìš”ì¸\"\n",
    "    - \"í•˜ì´ë‹‰ìŠ¤ ê°€ê²© ìƒìŠ¹ ìš”ì¸\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()  # OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©\n",
    "\n",
    "def decompose_query(query: str) -> list:\n",
    "    \"\"\"ë³µì¡í•œ ì¿¼ë¦¬ë¥¼ í•˜ìœ„ ì¿¼ë¦¬ë“¤ë¡œ ë¶„í•´\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"ë‹¹ì‹ ì€ ë³µì¡í•œ ì§ˆë¬¸ì„ í•˜ìœ„ ì§ˆë¬¸ë“¤ë¡œ ë¶„í•´í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ì£¼ì–´ì§„ ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ì í•©í•œ 2~4ê°œì˜ í•˜ìœ„ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´í•´ì£¼ì„¸ìš”.\n",
    "ê° í•˜ìœ„ ì§ˆë¬¸ì€ ë…ë¦½ì ìœ¼ë¡œ ê²€ìƒ‰ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì›ë³¸ ì§ˆë¬¸: {query}\n",
    "\n",
    "í•˜ìœ„ ì§ˆë¬¸ë“¤ 'í•œ ì¤„ì— í•˜ë‚˜ì”©, ë²ˆí˜¸ ì—†ì´):\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "    sub_queries = [q.strip() for q in result.strip().split('\\n') if q.strip()]\n",
    "    return sub_queries\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "complex_query = \"ì‚¼ì„±ì „ìì™€ SKí•˜ì´ë‹‰ìŠ¤ì˜ ë°˜ë„ì²´ ê¸°ìˆ ë ¥ê³¼ ì‹œì¥ ì ìœ ìœ¨ì„ ë¹„êµ ë¶„ì„í•´ì¤˜.\"\n",
    "sub_queries = decompose_query(complex_query)\n",
    "\n",
    "print(f\"ğŸ“ ì›ë³¸ ì§ˆë¬¸:{complex_query}\")\n",
    "print(f\"\\nğŸ”€ ë¶„í•´ëœ í•˜ìœ„ ì§ˆë¬¸ë“¤:\")\n",
    "for i, sq in enumerate(sub_queries, 1):\n",
    "    print(f\"    {i}. {sq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eccc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_decomposition(query: str, retriever, top_k: int = 3) -> list:\n",
    "    \"\"\"\n",
    "    ì¿¼ë¦¬ ë¶„í•´ + ê²€ìƒ‰ + ê²°ê³¼ í†µí•© íŒŒì´í”„ë¼ì¸\n",
    "    \"\"\"\n",
    "    # 1. ì¿¼ë¦¬ ë¶„í•´\n",
    "    sub_queries = decompose_query(query)\n",
    "    print(f\"ğŸ”€ '{query[:30]}...' â†’ {len(sub_queries)}ê°œ í•˜ìœ„ ì¿¼ë¦¬ë¡œ ë¶„í•´\")\n",
    "\n",
    "    #2. ê° í™”ìœ„ ì¿¼ë¦¬ì— ëŒ€í•´ ê²€ìƒ‰\n",
    "    all_docs = []\n",
    "    seen_contents = set()\n",
    "\n",
    "    for sq in sub_queries:\n",
    "        docs = retriever.invoke(sq)\n",
    "        for doc in docs:\n",
    "            # ì¤‘ë³µ ì œê±°\n",
    "            content_hash = hash(doc.page_content[:200])\n",
    "            if content_hash not in seen_contents:\n",
    "                seen_contents.add(content_hash)\n",
    "                all_docs.append(doc)\n",
    "    \n",
    "    print(f\"ğŸ—’ï¸ ì´ {len(all_docs)}ê°œ ê³ ìœ  ë¬¸ì„œ ê²€ìƒ‰ë¨\")\n",
    "\n",
    "    # 3. Rerankerë¡œ ìµœì¢… ì •ë ¬ (ì„ íƒì )\n",
    "    if len(all_docs) > top_k:\n",
    "        final_docs = reranker.compress_documents(all_docs, query)\n",
    "    else:\n",
    "        final_docs = all_docs[:top_k]\n",
    "    \n",
    "    return final_docs\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "docomposed_results = retrieve_with_decomposition(\n",
    "    \"ì¸ê³µì§€ëŠ¥ì˜ ì¥ë‹¨ì ê³¼ ë¯¸ë˜ ë°œì „ ë°©í–¥ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\",\n",
    "    hybrid_retriever\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Œ ìµœì¢… ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "for i, doc in enumerate(decomposed_results, 1):\n",
    "    print(f\"   {i}. [{doc.metadata.get('source', 'unknown')}] {doc.page_content[:80]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e37f90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e4e52",
   "metadata": {},
   "source": [
    "#### 6. RAG Chain êµ¬ì„± ë° í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59337af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# ìµœì¢… Generation Chain ì—°ê²°\n",
    "\n",
    "# LLM ì •ì˜\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=rerank_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "response = rag_chain.invoke({\"query\": \"í•œêµ­ì˜ êµìœ¡ ì œë„ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\"})\n",
    "print(f\"ğŸ¤– ë‹µë³€:\\n{response['result']}\")\n",
    "print(f\"\\nğŸ—’ï¸ ì°¸ì¡°í•œ ë¬¸ì„œ ì¶œì²˜: {[doc.metadata.get('source', 'unknown') for doc in response['source_documents']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8385476d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0cf6c2",
   "metadata": {},
   "source": [
    "#### 7. Synthetic Testset Generation (í‰ê°€ ë°ì´í„° ìƒì„±)\n",
    "\n",
    "í‰ê°€ íŒŒíŠ¸ ì…ë‹ˆë‹¤.(without RAGAS)\n",
    "\n",
    "\"ì •ë‹µì§€(Ground Truth)ê°€ ì—†ëŠ”ë° ì–´ë–»ê²Œ í‰ê°€í•˜ë‚˜ìš”?\" â†’ **LLMì„ ì‹œì¼œì„œ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì œë¥¼ ì¶œì œí•˜ë©´ ë©ë‹ˆë‹¤.**\n",
    "\n",
    "ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 'ì§ˆë¬¸'ê³¼ 'ëª¨ë²” ë‹µì•ˆ'ì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94318f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def generate_test_questions(docs, num_questions=5):\n",
    "    \"\"\" ë¬¸ì„œì—ì„œ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸/ë‹µë³€ ìŒ ìƒì„±\"\"\"\n",
    "\n",
    "    # ë¬¸ì„œ ë‚´ìš© í•©ì¹˜ê¸°\n",
    "    combined_text = \"\\n\\n\".join([doc.page_content for doc in docs[:30]])\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°\n",
    "    if len(combined_text) > 15000:\n",
    "        combined_text = combined_text[:15000]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0.7,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"ë‹¹ì‹ ì€ ë¬¸ì„œë¥¼ ì½ê³  í…ŒìŠ¤íŠ¸ ë¬¸ì œë¥¼ ì¶œì œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì½ê³  {num_questions}ê°œì˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë¬¸ì„œ:\n",
    "{combined_text}\n",
    "\n",
    "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´)\n",
    "[\n",
    "    {{\"question\": \"ì§ˆë¬¸1\", \"answer\": \"ë‹µë³€1\"}},\n",
    "    {{\"question\": \"ì§ˆë¬¸2\", \"answer\": \"ë‹µë³€2\"}}\n",
    "]\n",
    "\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "\n",
    "    # JSON íŒŒì‹±\n",
    "    try:\n",
    "        # í˜¹ì‹œ ```json``` ê°™ì€ ë§ˆí¬ë‹¤ìš´ì´ ìˆìœ¼ë©´ ì œê±°\n",
    "        result = result.strip()\n",
    "        if result.startswith(\"```\"):\n",
    "            result = result.split(\"```\")[1]\n",
    "            if result.startswith(\"json\"):\n",
    "                result = result[4:]\n",
    "        \n",
    "        qa_pairs = json.loads(result)\n",
    "        return qa_pairs\n",
    "    except:\n",
    "        print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ ì‘ë‹µ:\")\n",
    "        print(result)\n",
    "        return []\n",
    "\n",
    "# ì‹¤í–‰\n",
    "print(\"ğŸ¤– AIê°€ ë¬¸ì„œë¥¼ ì½ê³  ì‹œí—˜ ë¬¸ì œë¥¼ ì¶œì œ ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "print(\"    âŒ› ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...\")\n",
    "\n",
    "qa_pairs = generate_test_questions(splitted_docs, num_questions=5)\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "test_df = pd.DataFrame(qa_pairs)\n",
    "test_df.columns = ['user_input', 'reference']\n",
    "\n",
    "print(f\"\\nâœ… {len(test_df)}ê°œì˜ í…ŒìŠ¤íŠ¸ ë¬¸ì œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1646c432",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85c65e",
   "metadata": {},
   "source": [
    "#### 8. ğŸ†• Evaluation (ì •ëŸ‰ í‰ê°€) + ë©”íŠ¸ë¦­ í•´ì„ ê°€ì´ë“œ\n",
    "\n",
    "PPT 56ë²ˆ ìŠ¬ë¼ì´ë“œì˜ ì£¼ìš” í‰ê°€ ë©”íŠ¸ë¦­ì„ ì‹¤ì œë¡œ ì¸¡ì •í•©ë‹ˆë‹¤. ë‹¤ë§Œ ì‹¬í”Œí•¨ì„ ìœ„í•´ llm-as-judgeë¥¼ ì‚¬ìš©í•´ë´…ì‹œë‹¤!\n",
    "\n",
    "#### ğŸ“Š RAGAS í•µì‹¬ ë©”íŠ¸ë¦­ í•´ì„ ê°€ì´ë“œ\n",
    "\n",
    "|ë©”íŠ¸ë¦­|ì¸¡ì •ëŒ€ìƒ|ì˜ë¯¸|ë‚®ì„ ë•Œ ì›ì¸|\n",
    "|----|----|----|----|\n",
    "|**Faithfulness**|ìƒì„± ëª¨ë“ˆ|ë‹µë³€ì´ ê²€ìƒ‰ëœ Contextì— **ì¶©ì‹¤**í•œê°€? (í• ë£¨ì‹œë„¤ì´ì…˜ ì²´í¬)|LLMì´ Context ì™¸ ì •ë³´ë¡œ ë‹µë³€ ìƒì„±|\n",
    "|**Answer Relevancy**|ìƒì„± ëª¨ë“ˆ|ë‹µë³€ì´ ì§ˆë¬¸ì˜ **ì˜ë„ì— ë¶€í•©**í•˜ëŠ”ê°€?|ì§ˆë¬¸ê³¼ ë¬´ê´€í•œ ë‚´ìš© í¬í•¨|\n",
    "|**Context Recall**|ê²€ìƒ‰ ëª¨ë“ˆ|ì •ë‹µì— í•„ìš”í•œ ì •ë³´ê°€ Contextì— **í¬í•¨**ë˜ì—ˆëŠ”ê°€?|Retrieverê°€ ê´€ë ¨ ë¬¸ì„œ ëˆ„ë½|\n",
    "|**Context Precision**|ê²€ìƒ‰ ëª¨ë“ˆ|ê²€ìƒ‰ëœ Contextê°€ **ê´€ë ¨ì„± ë†’ì€ ìˆœì„œ**ë¡œ ì •ë ¬ë˜ì—ˆëŠ”ê°€?|ë…¸ì´ì¦ˆ ë¬¸ì„œê°€ ìƒìœ„ì— ìœ„ì¹˜|\n",
    "\n",
    "#### ğŸ¯ ëª©í‘œ ì ìˆ˜ ê°€ì´ë“œë¼ì¸\n",
    "- **0.8 ì´ìƒ**: ìš°ìˆ˜ (Production Ready)\n",
    "- **0.6-0.8**: ì–‘í˜¸ (ê°œì„  ì—¬ì§€ ìˆìŒ)\n",
    "- **0.6 ë¯¸ë§Œ**: ê°œì„  í•„ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846e2556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS ì—†ì´ ê°„ë‹¨í•œ í‰ê°€ (LLM ê¸°ë°˜)\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def simple_evalute(question, answer, reference, context):\n",
    "    \"\"\"LLMì„ ì´ìš©í•œ ê°„ë‹¨í•œ í‰ê°€\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"ë‹¤ìŒ RAG ì‹œìŠ¤í…œì˜ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "ì •ë‹µ(ì°¸ì¡°): {reference}\n",
    "RAG ë‹µë³€: {answer}\n",
    "ê²€ìƒ‰ëœ ë¬¸ì„œ: {context[:500]}...\n",
    "\n",
    "ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ 1-5ì  í‰ê°€ (JSONìœ¼ë¡œë§Œ ì‘ë‹µ):\n",
    "- faithfulness: ë‹µë³€ì´ ê²€ìƒ‰ ë¬¸ì„œì— ì¶©ì‹¤í•œê°€?\n",
    "- relevancy: ë‹µë³€ì´ ì§ˆë¬¸ì— ì ì ˆí•œê°€?\n",
    "-  correctness: ë‹µë³€ì´ ì •ë‹µê³¼ ì¼ì¹˜í•˜ëŠ”ê°€?\n",
    "\n",
    "{{\"faithfulness\": ì ìˆ˜, \"relevancy\": ì ìˆ˜, \"correctness\": ì ìˆ˜, \"comment\": \"í•œì¤„í‰\"}}\"\"\"\n",
    "        }]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "print(\"ğŸ“Š RAG í‰ê°€ ì§„í–‰ ì¤‘...\")\n",
    "results = []\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    q = row['user_input']\n",
    "    ref = row['reference']\n",
    "\n",
    "    # RAGë¡œ ë‹µë³€ ìƒì„±\n",
    "    rag_result = rag_chain.invoke([\"query\": q])\n",
    "    answer = rag_result['result']\n",
    "    context = \" \".join([doc.page_content for doc in rag_result['source_documents']])\n",
    "\n",
    "    # í‰ê°€\n",
    "    eval_result = simple_evalute(q, answer, ref, context)\n",
    "    print(f\"   ë¬¸ì œ {i+1} í‰ê°€ ì™„ë£Œ\")\n",
    "    results.append({\n",
    "        'question': q,\n",
    "        'answer': answer,\n",
    "        'evaluation': eval_result\n",
    "    })\n",
    "\n",
    "print(\"\\nâœ… í‰ê°€ ì™„ë£Œ!\")\n",
    "for r in results:\n",
    "    print(f\"\\nğŸ“ Q: {r['question'][:50]}...\")\n",
    "    print(f\"   í‰ê°€: {r['evaluation']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9caeb2b",
   "metadata": {},
   "source": [
    "#### ğŸ” ê²°ê³¼ ë¶„ì„ ë° ê°œì„  ë°©í–¥\n",
    "\n",
    "|**ë¬¸ì œ ìƒí™©**|**ë‚®ì€ ë©”íŠ¸ë¦­**|**ê°œì„  ë°©í–¥**|\n",
    "|----|----|----|\n",
    "|í• ë£¨ì‹œë„¤ì´ì…˜ ë°œìƒ|Faithfulness â†“|í”„ë¡¬í”„íŠ¸ì— \"Contextì— ì—†ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  ë‹µë³€\" ì§€ì‹œ ì¶”ê°€|\n",
    "|ì—‰ëš±í•œ ë‹µë³€|Answer Relevancy â†“|ì¿¼ë¦¬ ì¬ì‘ì„±(Query Rewrite) ë„ì…|\n",
    "|ê´€ë ¨ ë¬¸ì„œ ëˆ„ë½|Context Recall â†“|Retriever kê°’ ì¦ê°€, Hybrid ê°€ì¤‘ì¹˜ ì¡°ì •|\n",
    "|ë…¸ì´ì¦ˆ ë¬¸ì„œ ìƒìœ„|Context Precision â†“|Reranker ëª¨ë¸ êµì²´, Fine-tuning|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ca068",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02662444",
   "metadata": {},
   "source": [
    "#### 9. ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¹„êµ ì‹¤í— (Naive vs Advanced)\n",
    "ì§€ê¸ˆê¹Œì§€ êµ¬ì¶•í•œ ë‹¤ì–‘í•œ íŒŒì´í”„ë¼ì¸ì˜ ì„±ëŠ¥ì„ í•œëˆˆì— ë¹„êµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9523fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ì–‘í•œ Retriever íŒŒì´í”„ë¼ì¸ ì •ì˜\n",
    "pipelines = {\n",
    "    \"1. BM25 Only (Baseline)\": bm25_retriever,\n",
    "    \"2. Vector Only (Naive RAG)\": vector_retriever,\n",
    "    \"3. Hybrid (BM25 + Vector)\": hybrid_retriever,\n",
    "    \"4. Hybrid + Reranker (Advanced)\": reranker_retriever\n",
    "}\n",
    "\n",
    "test_query = \"ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ê³¼ í™œìš© ì‚¬ë¡€ì— ëŒ€í•´ ì•Œë ¤ì¤˜\"\n",
    "\n",
    "print(f\"ğŸ” í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: '{test_query}'\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for name, retriever in pipelines.items():\n",
    "    docs = retriever.invoke(test_query)\n",
    "\n",
    "    print(f\"\\nğŸ“Œ {name}\")\n",
    "    print(f\"   ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}\")\n",
    "\n",
    "    if docs:\n",
    "        print(f\"   Top-1 ë¯¸ë¦¬ë³´ê¸°: {docs[0].page_content[:60]}...\")\n",
    "        comparison_results.append({\n",
    "            \"Pipeline\": name,\n",
    "            \"ë¬¸ì„œ ìˆ˜\": len(docs),\n",
    "            \"Top-1 ì¶œì²˜\": docs[0].metadata.get('source', 'unknown')\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nğŸ“Š íŒŒì´í”„ë¼ì¸ ë¹„êµ ìš”ì•½:\")\n",
    "display(pd.DataFrame(comparison_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57153024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ì–‘í•œ Retriever íŒŒì´í”„ë¼ì¸ ì •ì˜ ë° LLM as Judge í‰ê°€\n",
    "prpilines = {\n",
    "    \"1. BM25 Only (Baseline)\": bm25_retriever,\n",
    "    \"2. Vector Only (Naive RAG)\": vector_retriever,\n",
    "    \"3. Hybrid (BM25 + Vector)\": hybrid_retriever,\n",
    "    \"4. Hybrid + Reranker (Advanced)\": rerank_retriever\n",
    "}\n",
    "\n",
    "test_query = \"ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ê³¼ í™œìš© ì‚¬ë¡€ì— ëŒ€í•´ ì•Œë ¤ì¤˜\"\n",
    "\n",
    "print(f\"ğŸ” í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: '{test_query}'\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_results = []\n",
    "llm_eval_results = []\n",
    "\n",
    "for name, retriever in pipelines.items():\n",
    "    docs = retriever.invoke(test_query)\n",
    "    answer = \"\"\n",
    "    context = \"\"\n",
    "    if docs:\n",
    "        # RAG ë‹µë³€ ìƒì„± (ì˜ˆì‹œ: ì²« ë¬¸ì„œ ë‚´ìš© í™œìš©)\n",
    "        context = \" \".join([doc.page_content for doc in docs])\n",
    "        # ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì—°ê²°\n",
    "        answer = docs[0].page_content[:300]\n",
    "    else:\n",
    "        answer = \"ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\"\n",
    "        context = \"\"\n",
    "    print(f\"\\nğŸ“Œ {name}\")\n",
    "    print(f\"   ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}\")\n",
    "    if docs:\n",
    "        print(f\"   Top-1 ë¯¸ë¦¬ë³´ê¸°: {docs[0].page_content[:60]}...\")\n",
    "        comparison_results.append({\n",
    "            \"Pipeline\": name,\n",
    "            \"ë¬¸ì„œ ìˆ˜\": len(docs),\n",
    "            \"Top-1 ì¶œì²˜\": docs[0].metadata.get('source', 'unknown')\n",
    "        })\n",
    "    # LLM as Judge í‰ê°€\n",
    "    eval_result = simple_evaluate(test_query, answer, \"(ì°¸ì¡° ì—†ì‘)\", context)\n",
    "    print(f\"   LLM í‰ê°€: {eval_result}\")\n",
    "    llm_eval_results.append({\n",
    "        \"Pipeline\": name,\n",
    "        \"LLM í‰ê°€\": eval_result\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nğŸ“Š íŒŒì´í”„ë¼ì¸ ë¹„êµ ìš”ì•½:\")\n",
    "display(pd.DataFrame(comparison_results))\n",
    "print(\"\\nğŸ¤– LLM as Judge í‰ê°€ ìš”ì•½:\")\n",
    "display(pd.DataFrame(llm_eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a665d9c0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48ec4c",
   "metadata": {},
   "source": [
    "## ğŸ‰ ê²°ë¡  ë° ê³ ì°°\n",
    "#### ì˜¤ëŠ˜ ë°°ìš´ í•µì‹¬ ê°œë…\n",
    "1. **ê²€ìƒ‰ ë°©ì‹ì˜ ì§„í™”**\n",
    "- BM25 (í‚¤ì›Œë“œ) â†’ Vector (ì˜ë¯¸) â†’ Hybrid (ê²°í•©) â†’ Rerank (ì •ë°€í™”)\n",
    "2. **Query Decomposition**\n",
    "- ë³µì¡í•œ ì§ˆë¬¸ì„ ë¶„í•´í•˜ì—¬ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ\n",
    "- PPTì˜ \"ì‚¼ì„±ì „ì vs í•˜ì´ë‹‰ìŠ¤\" ì˜ˆì‹œì²˜ëŸ¼ ì‹¤ë¬´ì—ì„œ ìì£¼ ì‚¬ìš©\n",
    "3. **2-Stage Retrieval**\n",
    "- Bi-Encoderë¡œ ë¹ ë¥´ê²Œ í›„ë³´ ì¶”ì¶œ â†’ Cross-Encoderë¡œ ì •ë°€ ì¬ì •ë ¬\n",
    "4. **RAGAS í‰ê°€**\n",
    "- Faithfulness: í• ë£¨ì‹œë„¤ì´ì…˜ ì²´í¬\n",
    "- Answer Relevancy: ì§ˆë¬¸ ì˜ë„ ë¶€í•©ë„\n",
    "- Context Recall/Precision: ê²€ìƒ‰ í’ˆì§ˆ\n",
    "\n",
    "#### PPTì˜ í•µì‹¬ ë©”ì‹œì§€\n",
    "```\n",
    "\"ì—”ì§€ë‹ˆì–´ë§ì— ë¬´ì¡°ê±´ì ì¸ í•´ë‹µì€ ì—†ì§€ë§Œ, ëª©ì ì— ë§ëŠ” ìµœì í™”ëŠ” ì¡´ì¬í•©ë‹ˆë‹¤.\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}