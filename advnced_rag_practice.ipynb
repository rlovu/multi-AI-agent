{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4861bd20",
   "metadata": {},
   "source": [
    "## ëŒ€ìš©ëŸ‰ ë¹„ì •í˜• ë°ì´í„° ê¸°ë°˜ Advanced RAG êµ¬ì¶• ë° í‰ê°€\n",
    "#### ê°•ì˜ ëª©í‘œ\n",
    "1. **Real-World Data Handling**: ë‚˜ë¬´ìœ„í‚¤(êµ¬ì–´ì²´/ì§€ì‹) FinePDFs(ë¬¸ì–´ì²´/ì „ë¬¸ë¬¸ì„œ)ê°€ ì„ì¸ ë‘ê°œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "2. **Beyond Keyword Search**: ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­(BM25)ê³¼ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰(Vector Search)ì˜ ê²°ì •ì  ì°¨ì´ë¥¼ ì²´ê°í•©ë‹ˆë‹¤.\n",
    "3. **Hybrid Search**: BM25ì™€ Vector Searchë¥¼ ê²°í•©í•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
    "4. **Advanced Pipeline**: Retriever + Reranker êµ¬ì¡°ë¥¼ í†µí•´ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ê·¹ëŒ€í™”í•˜ëŠ” ê¸°ë²•ì„ ìµí™ë‹ˆë‹¤.\n",
    "5. **Query Decomposition**: ë³µì¡í•œ ì§ˆì˜ë¥¼ ë¶„í•´í•˜ì—¬ ë” ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì–»ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "6. **Data-Driven Evalution**: ì •ë‹µì§€ê°€ ì—†ëŠ” ìƒí™©ì—ì„œ LLMì„ ì´ìš©í•´ *í•©ì„± ë°ì´í„°ì…‹(Synthetic Testset)*ì„ ë§Œë“¤ê³  í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "#### ì‚¬ìš© ëª¨ë¸ ë° ë°ì´í„°\n",
    "- **LLM**: gpt-5-mini (High Performance & Low Cost)\n",
    "- **Data**: heegyu/namuwiki (General Knowledge) + HuggingFaceFW/finepdfs-edu (Domain Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4f814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (Jupyter í™˜ê²½ ê¶Œì¥ ë°©ì‹)\n",
    "\n",
    "# ë²„ì „ì„ ëª…ì‹œí•˜ì—¬ í˜¸í™˜ì„± ë¬¸ì œ ë°©ì§€\n",
    "\n",
    "%pip install -q \\\n",
    "    langchain==0.3.14 \\\n",
    "    langchain-openai==0.2.14 \\\n",
    "    langchain-huggingface==0.1.2 \\\n",
    "    langchain-community==0.3.14 \\\n",
    "    ragas==0.2.10 \\\n",
    "    datasets \\\n",
    "    sentence-transformers \\\n",
    "    tiktoken \\\n",
    "    rank_bm25 \\\n",
    "    pandas \\\n",
    "    faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0b2324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# API_KEY ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d7850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print API key\n",
    "# print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY'][:-15]}\" + \"*\" * 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbcaef5",
   "metadata": {},
   "source": [
    "## 1. Data Loading: 'í˜„ì‹¤ì ì¸' ë°ì´í„° ë¯¹ì‹±(Mixing)\n",
    "í˜„ì‹¤ì—ëŠ” ê¹”ë”í•˜ê²Œ ì •ì œëœ ë°ì´í„°ë§Œ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. **ì§€ì‹ ë°±ê³¼(Wiki)** ìŠ¤íƒ€ì¼ê³¼ **ë³´ê³ ì„œ(PDF)** ìŠ¤íƒ€ì¼ì˜ í…ìŠ¤íŠ¸ê°€ ì„ì—¬ì„œ, ë‚œì´ë„ê°€ ë†’ì€ í†µí•© ê²€ìƒ‰ í™˜ê²½ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5681a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘...\n",
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ 986677ê°œ ë¬¸ì„œ\n",
      "   - Wiki ì˜ˆì‹œ(ì´ 867024ê°œ): [ì¶œì²˜: ë‚˜ë¬´ìœ„í‚¤] ì œëª©: !\n",
      "\n",
      "#redirect ëŠë‚Œí‘œ\n",
      "...\n",
      "   - PDF ì˜ˆì‹œ(ì´ 119653ê°œ): [ì¶œì²˜: ë‚˜ë¬´ìœ„í‚¤] ì œëª©: 04-ALICIA\n",
      "\n",
      "[[íŒŒì¼:external/vignette4.wikia.nocookie.net/Alicia_sche...\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "print(\"ğŸ“¥ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘...\")\n",
    "\n",
    "raw_docs = []\n",
    "\n",
    "# [Source A] ë‚˜ë¬´ìœ„í‚¤ (General Knowledge)\n",
    "# íŠ¹ì§•: êµ¬ì–´ì²´, ë‹¤ì–‘í•œ ì£¼ì œ, ë©”íƒ€ë°ì´í„°ì— ì œëª© í¬í•¨\n",
    "wiki_stream = load_dataset(\"heegyu/namuwiki\", split=\"train\", streaming=True)\n",
    "for idx, data in enumerate(wiki_stream):\n",
    "    # if idx >= 10: break  # ì‹¤ìŠµ ì†ë„ë¥¼ ìœ„í•´ 100ê°œë§Œ ì‚¬ìš©, Memory & Computation ì—¬ìœ ê°€ ìˆë‹¤ë©´ ì „ë¶€ ì¨ë³´ê¸°\n",
    "    # print(f\"[{idx+1}/100] {data}\")\n",
    "    content = f\"[ì¶œì²˜: ë‚˜ë¬´ìœ„í‚¤] ì œëª©: {data['title']}\\n\\n{data['text']}\"\n",
    "    raw_docs.append(Document(page_content=content, metadata={\"source\": \"namuwiki\", \"title\": data['title']}))\n",
    "\n",
    "length_of_wiki = len(raw_docs)\n",
    "\n",
    "# for i, doc in enumerate(raw_docs):\n",
    "#     print(f\"[{i+1}/10] {doc}\")\n",
    "\n",
    "# [Source B] FinePDFs-Edu (Domain Documents)\n",
    "# íŠ¹ì§•: ë¬¸ì–´ì²´, ì „ë¬¸ìš©ì–´, ì„œì‹(Header/Footer) ë…¸ì´ì¦ˆ ì¡´ì¬\n",
    "pdf_stream = load_dataset(\"HuggingFaceFW/finepdfs-edu\", \"kor_Hang\", split=\"train\", streaming=True)\n",
    "for idx, data in enumerate(pdf_stream):\n",
    "    # if idx >= 100: break\n",
    "    # PDFëŠ” ì œëª©ì´ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš°ê°€ ë§ì•„ URLì„ ë©”íƒ€ë°ì´í„°ë¡œ ì‚¬ìš©\n",
    "    raw_docs.append(Document(page_content=data['text'], metadata={\"source\": \"finepdf\", \"url\": data['url']}))\n",
    "\n",
    "length_of_pdf = len(raw_docs) - length_of_wiki\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {len(raw_docs)}ê°œ ë¬¸ì„œ\")\n",
    "print(f\"   - Wiki ì˜ˆì‹œ(ì´ {length_of_wiki}ê°œ): {raw_docs[0].page_content[:80]}...\")\n",
    "print(f\"   - PDF ì˜ˆì‹œ(ì´ {length_of_pdf}ê°œ): {raw_docs[length_of_wiki].page_content[:80]}...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d49fc6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2587974",
   "metadata": {},
   "source": [
    "## 2. Advanced Chunking Strategy\n",
    "PPTì—ì„œ ê°•ì¡°í•œ **Chunking** ì „ëµì…ë‹ˆë‹¤.\n",
    "- **Attention Dilution ë°©ì§€**: ë„ˆë¬´ ê¸¸ë©´ LLMì´ í•µì‹¬ì„ ë†“ì¹©ë‹ˆë‹¤.\n",
    "- **Context Overlap**: ë¬¸ë§¥ì´ ëŠê¸°ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ Chunk_overlapì„ ë‘¡ë‹ˆë‹¤.\n",
    "- **Separators**: ë¬¸ë‹¨(\\n\\n) â†’ ì¤„ë°”ê¿ˆ(\\n) â†’ ë¬¸ì¥(.) ìˆœì„œë¡œ ì˜ë¯¸ ë‹¨ìœ„ë¥¼ ë³´ì¡´í•˜ë©° ìë¦…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PPT ì‹¤ë¬´ íŒ ë°˜ì˜: ì˜ë¯¸ ë‹¨ìœ„ ë³´ì¡´ì„ ìœ„í•œ ê³„ì¸µì  Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,  # ê²€ìƒ‰ì— ì ì ˆí•œ í¬ê¸° (í† í° ê¸°ì¤€ ì•„ë‹˜, ê¸€ì ìˆ˜ ê¸°ì¤€)\n",
    "    chunk_overlap=100,  # ì•ë’¤ ë¬¸ë§¥ ì—°ê²°ì„ ìœ„í•œ ì˜¤ë²„ë©\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # ì˜ë¯¸ ë‹¨ìœ„ ìš°ì„  ìˆœìœ„\n",
    ")\n",
    "\n",
    "splitted_docs = text_splitter.split_documents(raw_docs)\n",
    "print(f\"âœ‚ï¸ ì²­í‚¹ ê²°ê³¼: {len(raw_docs)}ê°œ ë¬¸ì„œ â†’ {len(splitted_docs)}ê°œ ì²­í¬ë¡œ ë¶„í• ë¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a613e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871fb8fe",
   "metadata": {},
   "source": [
    "## 3. ê²€ìƒ‰ ì—”ì§„ êµ¬ì¶•: BM25, Vector, Hybrid\n",
    "ì„¸ê°€ì§€ ê²€ìƒ‰ ë°©ì‹ì„ êµ¬ì¶•í•˜ê³  ë¹„êµí•©ë‹ˆë‹¤.\n",
    "\n",
    "|ë°©ì‹|íŠ¹ì§•|ì¥ì |ë‹¨ì |\n",
    "|----|----|----|----|\n",
    "|**BM25**|í‚¤ì›Œë“œ ë§¤ì¹­|ì •í™•í•œ ìš©ì–´ ê²€ìƒ‰ì— ê°•í•¨|ë™ì˜ì–´/ìœ ì‚¬ì–´ ì¸ì‹ ë¶ˆê°€|\n",
    "|**Vector**|ì˜ë¯¸ ê¸°ë°˜|ë¬¸ë§¥ì  ìœ ì‚¬ì„± íŒŒì•…|íŠ¹ì • í‚¤ì›Œë“œ ê²€ìƒ‰ì— ì•½í•¨|\n",
    "|**Hybrid**|BM25 + Vector ê²°í•©|ë‘ ì¥ì  ê²°í•©|ê°€ì¤‘ì¹˜ íŠœë‹ í•„ìš”|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e460837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 1. BM25 Retriever êµ¬ì¶•(í‚¤ì›Œë“œ ê¸°ë°˜)\n",
    "bm25_retriever = BM25Retriever.from_documents(splitted_docs)\n",
    "bm25_retriever.k = 5  # í›„ë³´êµ°ì„ ë„‰ë„‰í•˜ê²Œ\n",
    "\n",
    "# 2. Vector Store êµ¬ì¶• (ì˜ë¯¸ ê¸°ë°˜, FAISS ì‚¬ìš©)\n",
    "# OpenAI Embedding ì‚¬ìš©\n",
    "openai_embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splitted_docs,\n",
    "    embedding=openai_embedding\n",
    ")\n",
    "vector_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(\"âœ… BM25 & Vector(FAISS) ê²€ìƒ‰ ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666e3ed",
   "metadata": {},
   "source": [
    "#### 3.1 ğŸ†• Hybrid Search êµ¬í˜„ (PPT 23-24 ìŠ¬ë¼ì´ë“œ)\n",
    "**Î»â€¢BM25 + (1-Î»)â€¢Vector** í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì…ë‹ˆë‹¤.\n",
    "```\n",
    "ìµœì¢… ìŠ¤ì½”ì–´ = Î± * BM25_score + (1 - Î±) * Vector_score\n",
    "```\n",
    "LangChainì˜ EnsembleRetrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ RRF(Reciprocal Rank Fusion) ë°©ì‹ìœ¼ë¡œ ê²°í•©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "# Hybrid Retriever: BM25(í‚¤ì›Œë“œ) + Vector(ì˜ë¯¸) ê²°í•©\n",
    "# weights: [BM25 ê°€ì¤‘ì¹˜, Vector ê°€ì¤‘ì¹˜] - í•©ì´ 1ì´ ë  í•„ìš”ëŠ” ì—†ìŒ\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.4, 0.6]  # Vectorì— ì•½ê°„ ë” ê°€ì¤‘ì¹˜ (ì‚¬ì „ ì •ì˜ëœ ì§ˆë¬¸ Coverageì— ë”°ë¼ ì¡°ì •)\n",
    ")\n",
    "\n",
    "print(\"âœ… Hybrid Search ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"   - BM25 ê°€ì¤‘ì¹˜: 0.4 (í‚¤ì›Œë“œ ë§¤ì¹­)\")\n",
    "print(\"   - Vector ê°€ì¤‘ì¹˜: 0.6 (ì˜ë¯¸ ê¸°ë°˜)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45bcf72",
   "metadata": {},
   "source": [
    "#### 3.2 ê²€ìƒ‰ ë°©ì‹ ë¹„êµ ì‹¤í—˜\n",
    "ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ ì„¸ê°€ì§€ ê²€ìƒ‰ ë°©ì‹ì˜ ê²°ê³¼ë¥¼ ë¹„êµí•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_retrievers(query: str):\n",
    "    \"\"\"ì„¸ê°€ì§€ ê²€ìƒ‰ ë°©ì‹ ê²°ê³¼ ë¹„êµ\"\"\"\n",
    "    print(f\"ğŸ” ì§ˆë¬¸: '{query}'\\n\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    results = {\n",
    "        \"BM25 (í‚¤ì›Œë“œ)\": bm25_retriever.invoke(query),\n",
    "        \"Vector (ì˜ë¯¸)\": vector_retriever.invoke(query),\n",
    "        \"Hybrid (ê²°í•©)\": hybrid_retriever.invoke(queyr)\n",
    "    }\n",
    "\n",
    "    for method, docs in results.items():\n",
    "        print(f\"\\nğŸ“Œ [{method}] ìƒìœ„ 3ê°œ ê²°ê³¼:\")\n",
    "        print(\"-\" * 40)\n",
    "        for i, doc in enumerate(docs[:3], 1):\n",
    "            source = doc.metadata.get('source', 'unknown')\n",
    "            preview = doc.page_content[:100].replace('\\n', ' ')\n",
    "            print(f\"   {i}. [{source}] {preview}...\")\n",
    "        if not docs:\n",
    "            print(\"   â†’ ê²°ê³¼ ì—†ìŒ\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ 1: ì˜ë¯¸ë¡ ì  ì§ˆë¬¸(Vectorê°€ ìœ ë¦¬)\n",
    "results1 = compare_retrievers(\"í”„ë¦°í„° ì¶”ì²œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf9847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 2: íŠ¹ì • í‚¤ì›Œë“œ ì§ˆë¬¸ (BM25ê°€ ìœ ë¦¬)\n",
    "results2 = compare_retrievers(\"ëŒ€í•œë¯¼êµ­ í—Œë²• ì œ1ì¡°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 3: ë³µí•©ì ì¸ ì§ˆë¬¸ (Hybridê°€ ìœ ë¦¬)\n",
    "results3 = compare_retrievers(\"ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ê³¼ ë¯¸ë˜ ì „ë§\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
